\documentclass[11pt,a4paper]{article}

% -------------------------------------------------
% Packages
% -------------------------------------------------
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{mathrsfs}
\usepackage{enumitem}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}


% -------------------------------------------------
% Fancy colored theorem environments with tcolorbox
% + optional titles: \begin{theorem}[Name] ... \end{theorem}
% Title text = white for readability
% -------------------------------------------------
\usepackage{xcolor}
\usepackage{xparse}
\usepackage[most]{tcolorbox}
\usepackage{etoolbox}


\tcbuselibrary{theorems,breakable,skins}

% --- Color palette (tweak RGB if you like) ---
\definecolor{ThmNavy}{RGB}{12, 35, 64}     % theorem (darkest)
\definecolor{PropBlue}{RGB}{23, 79, 145}   % proposition
\definecolor{LemBlue}{RGB}{70, 130, 180}   % lemma
\definecolor{CorNavy}{RGB}{18, 55, 95}     % corollary

\definecolor{DefBlue}{RGB}{40, 95, 140}    % definition
\definecolor{ExBlue}{RGB}{55, 115, 165}    % example
\definecolor{RemGray}{RGB}{90, 90, 90}     % remark

% --- Common box geometry ---
\tcbset{
  mybox/.style={
    enhanced, breakable,
    boxrule=0.9pt, arc=2mm,
    left=2mm, right=2mm, top=1mm, bottom=1mm,
    fonttitle=\bfseries,
    coltitle=white,        % <-- white title text
    coltext=black!95,      % <-- readable body text
  },
  % helper: light body background + dark title bar
  mycolors/.style={
    colframe=#1,
    colback=#1!4,
    colbacktitle=#1,       % dark title background
  }
}

% ---------- Boxed base environments (do NOT use directly) ----------

\newtcbtheorem[number within=section]{theorembox}{Theorem}%
{mybox, mycolors=ThmNavy}{thm}

\newtcbtheorem[use counter from=theorembox]{lemmabox}{Lemma}%
{mybox, mycolors=LemBlue}{lem}

\newtcbtheorem[use counter from=theorembox]{propositionbox}{Proposition}%
{mybox, mycolors=PropBlue}{prop}

\newtcbtheorem[use counter from=theorembox]{corollarybox}{Corollary}%
{mybox, mycolors=CorNavy}{cor}

\newtcbtheorem[use counter from=theorembox]{definitionbox}{Definition}%
{mybox, mycolors=DefBlue, fontupper=\normalfont}{def}

\newtcbtheorem[use counter from=theorembox]{examplebox}{Example}%
{mybox, mycolors=ExBlue, fontupper=\normalfont}{ex}

\newtcbtheorem[use counter from=theorembox]{remarkbox}{Remark}%
{enhanced, breakable,
  boxrule=0pt, frame hidden,   % no border
  colback=white,               % no background tint
  left=0pt, right=0pt, top=0.5mm, bottom=0.5mm,
  fonttitle=\itshape,
  coltitle=black!70,
  fontupper=\normalfont,
}{rem}


% Define a borderless proof box
\newtcolorbox{proofboxauto}[1][]{%
  enhanced, breakable,
  boxrule=0pt, frame hidden,
  arc=2mm,
  left=2mm, right=2mm, top=1mm, bottom=1mm,
  colback=blue!12,
  coltext=black!95,
  #1
}

% Patch amsthm proof to be inside the box
\AtBeginEnvironment{proof}{\begin{proofboxauto}}
\AtEndEnvironment{proof}{\end{proofboxauto}}

% ---------- User-facing environments with optional [title] ----------

\NewDocumentEnvironment{theorem}{o}
{\begin{theorembox}{\IfValueTF{#1}{#1}{}}{}}
{\end{theorembox}}

\NewDocumentEnvironment{lemma}{o}
{\begin{lemmabox}{\IfValueTF{#1}{#1}{}}{}}
{\end{lemmabox}}

\NewDocumentEnvironment{proposition}{o}
{\begin{propositionbox}{\IfValueTF{#1}{#1}{}}{}}
{\end{propositionbox}}

\NewDocumentEnvironment{corollary}{o}
{\begin{corollarybox}{\IfValueTF{#1}{#1}{}}{}}
{\end{corollarybox}}

\NewDocumentEnvironment{definition}{o}
{\begin{definitionbox}{\IfValueTF{#1}{#1}{}}{}}
{\end{definitionbox}}

\NewDocumentEnvironment{example}{o}
{\begin{examplebox}{\IfValueTF{#1}{#1}{}}{}}
{\end{examplebox}}

\NewDocumentEnvironment{remark}{o}
{\begin{remarkbox}{\IfValueTF{#1}{#1}{}}{}}
{\end{remarkbox}}






\definecolor{stepblue}{HTML}{2F80ED} % light-ish blue
\newcommand{\Step}[1]{\par\medskip\noindent\textcolor{stepblue}{ Step #1.}\;}

\definecolor{stepblue}{HTML}{2F80ED} % light-ish blue
\newcommand{\LabelProof}[1]{\par\medskip\noindent\textcolor{stepblue}{ #1.}\;}

\geometry{margin=1in}

% -------------------------------------------------
% Theorem environments (numbered by chapter)
% -------------------------------------------------
%\newtheorem{theorem}{Theorem}[chapter]
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{corollary}[theorem]{Corollary}

%\theoremstyle{definition}
%\newtheorem{definition}[theorem]{Definition}
%\newtheorem{example}[theorem]{Example}

%\theoremstyle{remark}
%\newtheorem{remark}[theorem]{Remark}

% -------------------------------------------------
% Notation / macros
% -------------------------------------------------
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\Pp}{\Prob}
\newcommand{\R}{\mathbb{R}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\Ecal}{\mathcal{E}}
\newcommand{\supp}{\operatorname{supp}}
\newcommand{\Ind}{\mathbf{1}} % indicator symbol (use as \Ind_{A})
\newcommand{\pos}{^{+}} % Positive part

\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\F}{\mathcal{F}}

\newcommand{\transpose}{\mathsf{T}}
\newcommand{\pinv}{^{+}} % pseudo-inverse


\newcommand{\esssup}{\operatorname*{ess\,sup}}
\newcommand{\essinf}{\operatorname*{ess\,inf}}

\title{Seminar - Elliptic Optimal Control with Measures}
\author{Anderson Singulani}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
We consider elliptic optimal control problems with \emph{localized} actuation, modeled by measure-valued controls \(u\in\mathcal M(\Omega)\).
The primal problem minimizes a quadratic tracking term in \(L^2(\Omega)\) plus the total variation penalty \(\alpha\|u\|_{\mathcal M(\Omega)}\), subject to the Dirichlet state equation \(Ay=u\) in a very weak sense.
We recall well-posedness and Sobolev regularity for elliptic equations with measure data and use these properties to prove existence (and, under standard assumptions, uniqueness) of optimal controls.
A key step is a Fenchel-duality derivation of an equivalent predual formulation in a Hilbert space, where the nonsmooth measure norm becomes the box constraint \(\|p\|_\infty\le \alpha\).
This leads to KKT conditions and an active-set characterization of sparsity, with the multiplier identified as (minus) the optimal control.
An explicit one-dimensional gravity example is worked out, yielding a Dirac optimal control and a sharp no-control threshold.
Finally, we outline regularization and semismooth Newton / primal-dual active set methods for efficient numerical solution.
\end{abstract}



\tableofcontents

\section{Introduction}

In many applications, actuation is \emph{localized} rather than distributed.
Typical examples are point sources/sinks in diffusion processes, localized injection or removal of a species, sparse placement of control devices, or idealized loads in mechanics.
Mathematically, such controls are naturally modeled by \emph{finite (signed) Borel measures} on the spatial domain:
a Dirac mass represents a point actuator, finite sums of Diracs represent finitely many devices, and more general measures allow line- or surface-supported actuation.
A central goal is therefore to formulate, analyze, and compute optimal controls when the control variable lives in a measure space.

A second (and equally important) motivation is \emph{structure promotion}.
Replacing quadratic control costs by $L^1$-type costs is known to promote sparsity of optimal controls (i.e.\ large inactive regions / controls that vanish on sets of positive measure); see, e.g., \cite{Stadler2009L1,WachsmuthWachsmuth2011} (and, for the classical finite-dimensional analogue, \cite{Tibshirani1996}).
However, in PDE-constrained settings, an $L^1(\Omega)$ control space may be analytically inadequate:
boundedness in $L^1$ does not provide weak compactness, and minimizing sequences may fail to have weakly convergent subsequences.
This points to the space of bounded measures as the natural relaxation and closure of the model. 

\subsection{Framework}
We focus on elliptic state equations of the form
\begin{equation}\label{eq:state_intro}
Ay = u \quad \text{in }\Omega, 
\qquad y=0 \quad \text{on }\partial\Omega,
\end{equation}
where $A$ is a linear, second-order elliptic operator and $u$ is the control.
If $u$ is a measure, equation \eqref{eq:state_intro} must be interpreted in a weak/distributional sense: one tests against smooth functions and transfers derivatives onto the test function.
Intuitively, the elliptic operator acts as a \emph{smoothing map}:
even if $u$ is singular (e.g.\ a Dirac mass), the state $y$ is still a genuine function with Sobolev regularity.
This smoothing property makes the tracking functional $\frac12\|y-z\|_{L^2(\Omega)}^2$ meaningful.

The optimization problem we have in mind is the prototypical sparse elliptic control problem
\begin{equation}\label{eq:PM_intro}
\min_{u \in \mathcal{M}(\Omega)} 
\ \frac12\|y-z\|_{L^2(\Omega)}^2 + \alpha \|u\|_{\mathcal{M}(\Omega)}
\qquad \text{s.t. } Ay=u,
\end{equation}
where $\mathcal{M}(\Omega)$ denotes the space of bounded (signed) measures and $\|\cdot\|_{\mathcal{M}(\Omega)}$ is the total variation norm.
The term $\alpha\|u\|_{\mathcal{M}(\Omega)}$ penalizes the \emph{mass} of the control; informally, it encourages placing ``as little control as possible'' and thus produces sparse/low-dimensional structures (few point actuators, small active sets, etc.).

A major computational difficulty is that \eqref{eq:PM_intro} is \emph{nonsmooth} and is posed in a \emph{nonreflexive} Banach space.
Direct discretization of measures can be delicate.
A key idea (following the duality-based approach) is to avoid discretizing measures directly:
one derives an equivalent \emph{predual} problem in a Hilbert space, where the nonsmooth measure norm appears as a \emph{simple box constraint} on a dual variable.
This transforms \eqref{eq:PM_intro} into a smooth constrained minimization problem that is amenable to efficient Newton-type solvers after suitable regularization.

\subsection{Analytical pillars (what makes the theory work)}
The report is organized around three pillars:

\paragraph{(I) Elliptic equations with measure right-hand sides.}
A first step is to clarify in which sense \eqref{eq:state_intro} is solved for $u\in\mathcal{M}(\Omega)$ and which regularity and stability estimates hold.
The essential message is: \emph{measure data still yield well-defined solutions with Sobolev regularity}, and the solution map $u\mapsto y(u)$ is continuous from $\mathcal{M}(\Omega)$ (with its weak-$\ast$ topology) into suitable Sobolev/Lebesgue spaces.
This is the analytic backbone that allows us to formulate the tracking term in $L^2(\Omega)$.

\paragraph{(II) Existence (and sometimes uniqueness) of optimal controls in measure spaces.}
Given (I), one proves existence of minimizers for \eqref{eq:PM_intro} by the direct method of the calculus of variations:
take a minimizing sequence, extract a weak-$\ast$ convergent subsequence in $\mathcal{M}(\Omega)$, pass to the limit in the state equation and in the objective using lower semicontinuity and compactness.
Under standard assumptions, strict convexity of the tracking term yields uniqueness of the optimal state (and typically of the optimal control in the measure setting considered).

\paragraph{(III) Duality, predual formulation, and numerical solution.}
The central computational insight is that Fenchel duality yields a predual problem in a Hilbert space (typically $H^2(\Omega)\cap H^1_0(\Omega)$ for the measure case), with a pointwise constraint of the form $\|p\|_{C_0(\Omega)}\le \alpha$.
This predual viewpoint replaces the measure variable by a smooth variable subject to box constraints, enabling:
\begin{itemize}
  \item derivation of optimality systems with complementarity structure (active/inactive sets);
  \item Moreau--Yosida (or similar) regularization of the box constraints;
  \item semismooth Newton / primal-dual active set methods with fast local convergence.
\end{itemize}

\subsection{Roadmap of the report}
We proceed as follows.
In Section~\ref{sec:pde_measures} we review elliptic boundary value problems with measure data, emphasizing the weak/distributional formulation and the resulting regularity estimates.
In Section~\ref{sec:primal_PM} we establish existence (and discuss uniqueness) for the sparse control problem \eqref{eq:PM_intro}and derives the predual formulation. In section \ref{sec:KKT} we obtain the associated first-order optimality conditions. Next, we give in \ref{sec:example} an example with an explicit solution to make this discussion more tangible. Finally, Section~\ref{sec:numerics} presents the regularization strategy and semismooth Newton-type algorithms used to solve the resulting optimality systems efficiently, together with a short discussion of structural properties of the computed controls (sparsity, active sets, and comparison to quadratic-control formulations).

\section{Elliptic equations with measure right-hand sides}\label{sec:pde_measures}

Measure-valued right-hand sides arise naturally when sources or loads are
\emph{highly localized}.
A point actuator at $x_0\in\Omega$ is modeled by a Dirac mass $\delta_{x_0}$, and a
finite collection of actuators corresponds to a finite sum of Dirac measures.
More generally, line- or surface-supported actuation leads to measures concentrated
on lower-dimensional sets.
In PDE-constrained optimization this is precisely the situation in which it is natural
to allow the control $u$ to belong to the space $\mathcal{M}(\Omega)$ of bounded
Borel (Radon) measures. 

\subsection{Distributional and very weak solutions for measure data}\label{sec:dist_vs_veryweak}

When the right-hand side is a measure (e.g.\ a Dirac mass), the elliptic state equation
\[
Ay = u \quad\text{in }\Omega,\qquad y=0\quad\text{on }\partial\Omega,
\qquad u\in\mathcal{M}(\Omega),
\]
cannot be interpreted pointwise.
One therefore needs a weak notion of solution based on testing against smooth functions.
There are two closely related notions that appear in the literature:
\emph{distributional} solutions (common in PDE theory) and \emph{very weak} solutions
(common in PDE-constrained optimization with measure controls).
They differ mainly by the \emph{choice of test functions} and by how the boundary condition
is encoded.

\subsection*{Distributional solution}
We recall the standard PDE notion.

\begin{definition}[Distributional solution]\label{def:distributional}
Let $\Omega\subset\mathbb{R}^n$ be open, $A$ be a linear differential operator with formal adjoint $A^*$,
and let $u\in\mathcal{M}(\Omega)$.
A function $y\in L^1_{\mathrm{loc}}(\Omega)$ is called a \emph{distributional solution} of
\[
Ay=u \quad\text{in }\Omega
\]
if
\begin{equation}\label{eq:dist_def}
\int_\Omega y\,A^*\varphi\,dx \;=\; \int_\Omega \varphi\,du
\qquad \forall\,\varphi\in C_c^\infty(\Omega).
\end{equation}
\end{definition}

\paragraph{Remarks.}
\begin{itemize}
\item The test functions are compactly supported in $\Omega$, so \eqref{eq:dist_def} expresses only the
      \emph{interior PDE} and does \emph{not} encode boundary conditions.
\item In particular, for a Dirichlet problem one must impose $y|_{\partial\Omega}=0$ \emph{separately},
      e.g.\ by requiring $y$ to belong to a space with zero trace (when such a trace makes sense),
      or by selecting the solution via a Green's function / resolvent construction.
\end{itemize}
For measure right-hand sides, distributional formulations are standard; see, for example,
the measure-data elliptic theory in \cite{ponceEMS}.%

\subsection*{Very weak solution (Dirichlet problem)}
In optimal control with measure-valued controls it is convenient to use a formulation
that (i) allows a natural pairing with $u\in\mathcal{M}(\Omega)$ and (ii) incorporates the
Dirichlet boundary condition through the choice of test functions.

\begin{definition}[Very weak solution of the Dirichlet problem]\label{def:veryweak_dirichlet}
Let $\Omega\subset\mathbb{R}^n$ be bounded and let $u\in\mathcal{M}(\Omega)$.
A function $y\in L^1(\Omega)$ is called a \emph{very weak solution} of the Dirichlet problem
\[
Ay=u \quad\text{in }\Omega,\qquad y=0\quad\text{on }\partial\Omega,
\]
if
\begin{equation}\label{eq:veryweak_def}
\int_\Omega y\,A^*\phi\,dx \;=\; \int_\Omega \phi\,du
\qquad \forall\,\phi\in \mathcal{V},
\end{equation}
where the test space $\mathcal{V}$ consists of functions that
\begin{itemize}
\item satisfy the homogeneous boundary condition (in the trace sense), and
\item are regular enough so that the right-hand side pairing $\int_\Omega \phi\,du$ is meaningful.
\end{itemize}
A typical choice in the measure-control setting is
\[
\mathcal{V} := H^2(\Omega)\cap H^1_0(\Omega)
\quad\text{with}\quad
H^2(\Omega)\cap H^1_0(\Omega)\hookrightarrow C_0(\Omega)
\ \ (n\in\{2,3\}),
\]
so that $\phi$ is continuous (hence integrable against measures) and vanishes on $\partial\Omega$.
This is the framework adopted in \cite{ClasonKunisch2009}.
\end{definition}

\paragraph{Remarks.}
\begin{itemize}
\item In contrast to Definition~\ref{def:distributional}, test functions in \eqref{eq:veryweak_def}
      \emph{touch the boundary}, and the condition $\phi|_{\partial\Omega}=0$ is built into $\mathcal{V}$.
      In this sense, \eqref{eq:veryweak_def} is tailored to Dirichlet boundary conditions.
\item The name ``very weak'' emphasizes that we require only $y\in L^1(\Omega)$ and test against a
      space $\mathcal{V}$ designed to make the measure pairing well-defined.
\end{itemize}

\paragraph{How the two notions (Very weak and distributional solution) are related?}
The two notions are closely connected by the following proposition

\begin{proposition}[Very weak implies distributional (interior equation)]\label{prop:vw_implies_dist}
Assume $y\in L^1(\Omega)$ satisfies the very weak identity \eqref{eq:veryweak_def} for a test space
$\mathcal{V}$ containing $C_c^\infty(\Omega)$ (or approximating it).
Then $y$ is a distributional solution of $Ay=u$ in the sense of Definition~\ref{def:distributional}.
\end{proposition}

\begin{proof}[Proof Idea]
If $\varphi\in C_c^\infty(\Omega)\subset\mathcal{V}$, then \eqref{eq:veryweak_def} holds with $\phi=\varphi$,
which is exactly \eqref{eq:dist_def}.
If $C_c^\infty(\Omega)$ is not literally included in $\mathcal{V}$, one uses density/approximation arguments.
\hfill$\square$    
\end{proof}


\paragraph{Key difference.}
Distributional solutions encode only the PDE in the interior and require boundary conditions to be
imposed separately. Very weak solutions are formulated with test functions that already satisfy the
homogeneous boundary condition; hence the Dirichlet condition is incorporated into the definition.

\paragraph{Why we choose the very weak formulation for measure controls?}
In PDE-constrained optimization with $u\in\mathcal{M}(\Omega)$, the very weak formulation is preferred
for three practical reasons.

\paragraph{(1) The measure pairing is immediate and stable.}
The control space is $\mathcal{M}(\Omega)=C_0(\Omega)^*$, so for any $\phi\in C_0(\Omega)$ the duality pairing
$\langle u,\phi\rangle=\int_\Omega \phi\,du$ is well-defined and continuous.
By choosing $\mathcal{V}\hookrightarrow C_0(\Omega)$, the right-hand side in \eqref{eq:veryweak_def}
becomes the canonical dual pairing used in the optimization framework. \cite{ClasonKunisch2009}

\paragraph{(2) The standard $H^1_0$ weak formulation is generally too strong.}
A common weak formulation for $Ay=u$ would test against $v\in H^1_0(\Omega)$, requiring $u\in H^{-1}(\Omega)$.
However, for $n\ge 2$ a general measure $u\in\mathcal{M}(\Omega)$ does \emph{not} define a continuous linear
functional on $H^1_0(\Omega)$, i.e.\ $\mathcal{M}(\Omega)\not\subset H^{-1}(\Omega)$ in general.
Thus one cannot base the state equation on the standard variational formulation when $u$ is merely a measure.
The very weak formulation avoids this mismatch by testing against smoother functions that are continuous,
so that the measure pairing is always meaningful. \cite{ponceEMS}

\paragraph{(3) It aligns with duality/predual arguments and numerics.}
Clason--Kunisch derive the optimality system by Fenchel duality, leading to a predual variable living in
$H^2(\Omega)\cap H^1_0(\Omega)$ with pointwise constraints in $C_0(\Omega)$.
The identity \eqref{eq:veryweak_def} is exactly the PDE constraint written in the duality pairing
$\mathcal{M}(\Omega)\times C_0(\Omega)$, which is the natural setting for their analysis and for
regularization-based Newton-type solvers. \cite{ClasonKunisch2009}

\paragraph{Conclusion.}
Distributional solutions are the natural notion to express $Ay=u$ in the interior of $\Omega$.
For measure-valued controls under Dirichlet boundary conditions, the very weak formulation is the natural
choice because it (i) incorporates the boundary condition through the test space,
(ii) makes the measure pairing canonical via $\mathcal{M}(\Omega)=C_0(\Omega)^*$, and
(iii) matches the duality-based analysis and numerical methods used later.


\subsection{Measure space and duality pairing}
Let $\mathcal{M}(\Omega)$ denote the space of bounded Borel measures on $\Omega$,
equipped with the total variation norm $\|\mu\|_{\mathcal{M}}=|\mu|(\Omega)$.
By the Riesz representation theorem, $\mathcal{M}(\Omega)$ can be identified with
the dual of $C_0(\Omega)$ (continuous functions vanishing at the boundary / with
compact support, depending on the chosen convention), with the duality pairing
$\langle \mu,\varphi\rangle = \int_\Omega \varphi\,d\mu$ and the norm characterization
\[
\|\mu\|_{\mathcal{M}}=\sup\Bigl\{\int_\Omega \varphi\,d\mu:\ \varphi\in C_0(\Omega),\ \|\varphi\|_\infty\le 1\Bigr\}.
\]

\subsection{Dirichlet problem with measure datum: existence and Sobolev regularity}
For PDE-constrained control on bounded domains, we need a Dirichlet boundary
condition and a solution space with enough regularity to be used in the cost functional.
A convenient (and widely used) result is the Sobolev embedding of solutions for
measure data.

\begin{proposition}[Elliptic equation with measure data]\label{prop:elliptic_measure}
For every $u\in\mathcal{M}(\Omega)$, the equation $Ay=u$ has a unique very weak solution $y$.
Moreover,
\[
y \in W^{1,p}_0(\Omega)
\quad\text{for all}\quad 1\le p<\frac{n}{n-1},
\]
and there exists $C>0$ (independent of $u$) such that
\begin{equation}\label{eq:W1p_estimate}
\|y\|_{W^{1,p}(\Omega)} \le C\,\|u\|_{\mathcal{M}(\Omega)}
\qquad \forall\,1\le p<\frac{n}{n-1}.
\end{equation}
\end{proposition}


\begin{proof}[Proof sketch]
A standard strategy is approximation + uniform estimates + compactness:
\begin{enumerate}
\item \emph{Approximate the measure by smooth densities.}
There exists a sequence $(f_k)_k\subset C^\infty(\Omega)$ with $f_k\to\mu$ weakly
in the sense of measures (and with controlled $L^1$ norms). 
\item \emph{Solve the Dirichlet problems for smooth data.}
For each $k$, let $u_k\in W^{1,2}_0(\Omega)$ solve $-\Delta u_k=f_k$.
(Variational solvability for $L^2$ data is classical.) 
\item \emph{Uniform $W^{1,q}$-estimate.}
Using Stampacchia-type estimates and a duality argument (Littman--Stampacchia--Weinberger),
one obtains $\|u_k\|_{W^{1,q}}\le C\|f_k\|_{L^1}$ uniformly for every $q<n/(n-1)$,
hence uniformly in terms of $\|\mu\|_{\mathcal{M}}$. 
\item \emph{Compactness and passage to the limit.}
By Rellich--Kondrachov, extract a subsequence converging strongly in $L^q(\Omega)$
(and a.e.) to some $u$. 
Passing to the limit in the weak formulation yields that $u$ solves $-\Delta u=\mu$
(in the appropriate weak/distributional sense) with $u\in W^{1,q}_0(\Omega)$ and the stated estimate.
\end{enumerate}
Uniqueness follows from linearity plus the standard energy argument (or uniqueness of the variational solution).    
\end{proof}



\paragraph{Interpretation.}
In the elliptic control problem with $u\in\mathcal{M}(\Omega)$, Proposition~\ref{prop:elliptic_measure}
implies that the state associated with a measure control has Sobolev regularity
$y\in W^{1,q}_0(\Omega)$ for all $q<n/(n-1)$.
This is exactly the type of mapping property used in the optimal control analysis:
from $u^*\in\mathcal{M}(\Omega)$ one deduces $y^*\in W^{1,p}_0(\Omega)$ for $p<n/(n-1)$ gains additional regularity. 


\subsection{The solution operator and the mapping to $L^2(\Omega)$}
Define the linear \emph{control-to-state} operator
\[
S:\mathcal{M}(\Omega)\to W^{1,p}_0(\Omega),\qquad Su := y,
\]
where $y$ is the unique very weak solution from Proposition~\ref{prop:elliptic_measure}.
By \eqref{eq:W1p_estimate}, $S$ is bounded.

For the optimization problem with quadratic tracking term in $L^2(\Omega)$ we also need that
$Su\in L^2(\Omega)$. This follows from Sobolev embedding: choosing
$p\ge \frac{2n}{n+2}$ (which is possible in $n\in\{2,3\}$ while still having $p<\frac{n}{n-1}$),
we obtain a continuous embedding $W^{1,p}_0(\Omega)\hookrightarrow L^2(\Omega)$ and hence
\begin{equation}\label{eq:S_to_L2}
\|Su\|_{L^2(\Omega)} \le C\,\|u\|_{\mathcal{M}(\Omega)}.
\end{equation}
The compactness mechanisms typically used later (e.g.\ for existence of optimal controls)
are based on boundedness in $W^{1,p}_0(\Omega)$ together with Rellich--Kondrachov,
which yields strong convergence in $L^2$ along subsequences. \cite{ponceEMS}

\section{Optimal control problems in $\mathcal{M}(\Omega)$}\label{sec:primal_PM}

In many applications the control represents \emph{localized actuation}: point sources, sinks, injections, or devices that act on a small set compared to the domain.
A natural mathematical model for such effects is a \emph{measure-valued} right-hand side in the elliptic state equation.
On the optimization side, replacing quadratic control costs by an $\mathcal{M}(\Omega)$-norm (or, heuristically, an $L^1$-type cost) biases the optimizer towards controls that concentrate on small sets, i.e.\ sparse controls; see the structural discussion in \cite{ClasonKunisch2009}. 

\subsection{Primal problem}
Let $\Omega\subset\mathbb{R}^n$ ($n\in\{2,3\}$) be bounded with Lipschitz boundary and let $A$ be a linear second-order elliptic operator with homogeneous Dirichlet boundary condition.
Fix $z\in L^2(\Omega)$ and $\alpha>0$.
We consider the \emph{primal measure control problem}
\begin{equation}\label{eq:PM}
\tag{$P_M$}
\min_{u\in\mathcal{M}(\Omega)}\;
J(u):=\frac12\|y(u)-z\|_{L^2(\Omega)}^2+\alpha\|u\|_{\mathcal{M}(\Omega)}
\quad\text{s.t.}\quad Ay(u)=u \ \text{in }\Omega,\ \ y(u)=0 \ \text{on }\partial\Omega,
\end{equation}
where $y(u)$ denotes the unique very weak solution associated with $u$. In the following we will show that this problem has an unique solution.

\paragraph{Intuition}
The PDE constraint provides a solution operator
\[
S:\mathcal{M}(\Omega)\to W^{1,p}_0(\Omega)\hookrightarrow L^2(\Omega),
\qquad u\mapsto y(u),
\]
where $y(u)$ is understood in the \emph{very weak sense}.
The key point for existence is the following compactness mechanism:
a minimizing sequence $(u_n)$ is bounded in $\mathcal{M}(\Omega)$, hence admits a weak-$*$ convergent subsequence;
the corresponding states $(y_n=S(u_n))$ are bounded in $W^{1,p}_0(\Omega)$ and therefore precompact in $L^2(\Omega)$.
This gives strong convergence of the tracking term, while the measure norm is weak-$*$ lower semicontinuous.

\begin{proposition}[Existence and uniqueness of a minimizer]\label{prop:exist_PM}
Problem~\eqref{eq:PM} admits a unique minimizer $(y^*,u^*)\in L^2(\Omega)\times\mathcal{M}(\Omega)$.
\end{proposition}

\begin{proof}
\textbf{Step 1: Bounded minimizing sequence and weak-$*$ compactness.}
Let $(u_n)_{n\in\mathbb{N}}\subset\mathcal{M}(\Omega)$ be a minimizing sequence for $J$.
Since $(y,u)=(0,0)$ is feasible, we have
\[
\inf J \le J(0)=\frac12\|z\|_{L^2(\Omega)}^2,
\]
hence $\alpha\|u_n\|_{\mathcal{M}(\Omega)}\le J(u_n)\le C$ for all $n$, so $(u_n)$ is bounded in $\mathcal{M}(\Omega)$.
By Banach--Alaoglu, there exists a subsequence (not relabeled) and a $u^*\in\mathcal{M}(\Omega)$ such that
\[
u_n \xrightharpoonup{*} u^* \quad \text{in } \sigma(\mathcal{M}(\Omega),C_0(\Omega)).
\]

\textbf{Step 2: Compactness of states.}
Let $y_n:=y(u_n)$.
By the elliptic well-posedness in the very weak setting (Section~\ref{sec:veryweak_vs_dist}),
the sequence $(y_n)$ is bounded in $W^{1,p}_0(\Omega)$ for every $1\le p<\frac{n}{n-1}$.
Since $W^{1,p}_0(\Omega)\hookrightarrow L^2(\Omega)$ compactly for $n\in\{2,3\}$ and such $p$,
there exists a further subsequence and $y^*\in L^2(\Omega)$ such that
\[
y_n \to y^* \quad \text{strongly in } L^2(\Omega).
\]

\textbf{Step 3: Passage to the limit in the state equation.}
Let $\mathcal{V}\subset C_0(\Omega)$ be the test space used in the definition of very weak solution
(e.g.\ $\mathcal{V}=H^2(\Omega)\cap H^1_0(\Omega)$, cf.\ Remark~\ref{rem:V_into_C0}).
For every $\varphi\in\mathcal{V}$ the very weak formulation reads
\[
\int_\Omega y_n\, A^*\varphi\,dx \;=\; \int_\Omega \varphi\,du_n.
\]
The left-hand side converges to $\int_\Omega y^* A^*\varphi\,dx$ by strong $L^2$ convergence of $y_n$
and the fact that $A^*\varphi\in L^2(\Omega)$.
The right-hand side converges to $\int_\Omega \varphi\,du^*$ by weak-$*$ convergence in $\mathcal{M}(\Omega)$
since $\varphi\in C_0(\Omega)$.
Thus $y^*$ solves $Ay^*=u^*$ in the very weak sense, i.e.\ $y^*=y(u^*)$.

\textbf{Step 4: Lower semicontinuity and optimality.}
By strong convergence, $\|y_n-z\|_{L^2}^2\to\|y^*-z\|_{L^2}^2$.
Moreover, the total variation norm is weak-$*$ lower semicontinuous:
$\|u^*\|_{\mathcal{M}(\Omega)}\le \liminf_{n\to\infty}\|u_n\|_{\mathcal{M}(\Omega)}$.
Hence
\[
J(u^*) \le \liminf_{n\to\infty} J(u_n) = \inf J,
\]
so $u^*$ is optimal.

\textbf{Step 5: Uniqueness.}
The mapping $u\mapsto y(u)$ is linear and injective (for elliptic $A$ with Dirichlet condition),
and the term $\frac12\|y(u)-z\|_{L^2}^2$ is strictly convex in $y$.
Together with convexity of $\|u\|_{\mathcal{M}(\Omega)}$, this yields uniqueness of the minimizer.
\end{proof}

\subsection{Deriving the predual problem from the primal problem}\label{sec:derive_predual}

The primal problem is posed in the non-reflexive space $\mathcal{M}(\Omega)$ and contains
the nonsmooth term $\|u\|_{\mathcal{M}(\Omega)}$. The insight in \cite{ClasonKunisch2009} is to consider the predual of \ref{eq:PM} because its formulation replaces the measure variable
by a function variable $p\in H^2(\Omega)\cap H^1_0(\Omega)$ subject to the simple constraint
$\|p\|_\infty\le \alpha$. This section explains how this box constraint is \emph{already hidden}
in the primal formulation and can be made explicit via convex duality.

\subsection*{Step 1: Write the primal in reduced form}
Let $S:\mathcal{M}(\Omega)\to L^2(\Omega)$ be the control-to-state map $Su=y(u)$ solving
$Ay=u$ with homogeneous Dirichlet boundary condition (in the very weak sense).
Then the primal problem can be written as
\begin{equation}\label{eq:PM_reduced}
\min_{u\in\mathcal{M}(\Omega)} \;
\underbrace{\frac12\|Su-z\|_{L^2(\Omega)}^2}_{=:f(Su)}
\;+\;
\underbrace{\alpha\|u\|_{\mathcal{M}(\Omega)}}_{=:g(u)}.
\end{equation}
This has the abstract form $\min_{u} f(Lu)+g(u)$ with $L=S$.

\subsection*{Step 2: Dual representation of the quadratic tracking term}
The functional $f(y)=\frac12\|y-z\|_{L^2}^2$ has the classical convex conjugate representation \cite{ekelandtemam1999}
\begin{equation}\label{eq:quad_dual_rep}
f(y)=\sup_{w\in L^2(\Omega)}\Bigl\{\langle y,w\rangle_{L^2}-f^*(w)\Bigr\},
\qquad
f^*(w)=\frac12\|w\|_{L^2}^2+\langle z,w\rangle_{L^2}.
\end{equation}
Insert \eqref{eq:quad_dual_rep} into \eqref{eq:PM_reduced} to obtain the saddle form
\begin{equation}\label{eq:saddle_start}
\inf_{u\in\mathcal{M}(\Omega)}\sup_{w\in L^2(\Omega)}
\Bigl[
\langle Su,w\rangle_{L^2}
-\Bigl(\frac12\|w\|_{L^2}^2+\langle z,w\rangle_{L^2}\Bigr)
+\alpha\|u\|_{\mathcal{M}}
\Bigr].
\end{equation}

\subsection*{Step 3: Move $S$ to the adjoint side (appearance of the predual variable)}
Since $S$ is linear and bounded, $\langle Su,w\rangle_{L^2}$ can be written using the adjoint operator
$S^*$:
\[
\langle Su,w\rangle_{L^2} = \langle u, S^*w\rangle_{\mathcal{M},C_0},
\]
where $\langle u,\phi\rangle_{\mathcal{M},C_0}:=\int_\Omega \phi\,du$.
In elliptic settings, $S^*w$ is the (Dirichlet) adjoint state, i.e.\ the unique solution $p$ of
\begin{equation}\label{eq:adjoint_p}
A^*p = w \quad\text{in }\Omega,\qquad p=0\quad\text{on }\partial\Omega,
\end{equation}
and for $n\le 3$ one has $p\in H^2(\Omega)\cap H^1_0(\Omega)\hookrightarrow C_0(\Omega)$,
so the measure pairing $\langle u,p\rangle$ is well-defined.
Thus, we may identify
\[
p := S^*w \in H^2(\Omega)\cap H^1_0(\Omega)
\qquad\text{and}\qquad
w = A^*p.
\]
In particular, $\|w\|_{L^2}=\|A^*p\|_{L^2}$ and $\langle z,w\rangle=\langle z,A^*p\rangle$.

the saddle formulation \eqref{eq:saddle_start} can be rewritten as
\begin{equation}\label{eq:inf_sup_step3}
\inf_{u\in\mathcal{M}(\Omega)}\ \sup_{p\in H^2(\Omega)\cap H^1_0(\Omega)}
\Bigl[
\langle u,p\rangle_{\mathcal{M},C_0}
-\frac12\|A^*p\|_{L^2(\Omega)}^2
-\langle z,A^*p\rangle_{L^2(\Omega)}
+\alpha\|u\|_{\mathcal{M}(\Omega)}
\Bigr],
\end{equation}
where $\langle u,p\rangle_{\mathcal{M},C_0}:=\int_\Omega p\,du$.
Equivalently, completing the square in the $p$-dependent quadratic terms yields
\begin{equation}\label{eq:inf_sup_step3_square}
\inf_{u\in\mathcal{M}(\Omega)}\ 
\Bigl[
-\frac12\|A^*p+z\|_{L^2(\Omega)}^2
+\frac12\|z\|_{L^2(\Omega)}^2
\Bigr].
\end{equation}


\subsection*{Step 4: Minimize out the measure (conjugate of the measure norm)}
Next, let $w$ (equivalently $p$) be arbitrary and fixed  in \eqref{eq:saddle_start}. The dependence on $u$ is
\[
\inf_{u\in\mathcal{M}(\Omega)}
\Bigl\{ \langle u,p\rangle_{\mathcal{M},C_0} + \alpha\|u\|_{\mathcal{M}} \Bigr\}.
\]
A standard conjugacy fact for norm is \cite{ekelandtemam1999})
\[
(\alpha\|\cdot\|_X)^*(p)
=\sup_{u\in X}\{\langle u,p\rangle_{\mathcal{M},C_0}-\alpha\|u\|_X\}
= I_{\{\|\phi\|_{X^*}\le \alpha\}}(p).\label{eq:saddle_interm}
\]

In our setting $X=\mathcal{M}(\Omega)=C_0(\Omega)^*$ thus the convex conjugate of $\alpha\|\cdot\|_{\mathcal{M}}$ is the indicator
of the $\|\cdot\|_\infty$-ball in $C_0(\Omega)$.
Equivalently,
\begin{equation}\label{eq:measure_conjugate_fact}
\sup_{u\in\mathcal{M}(\Omega)} \bigl\{\langle u,p\rangle_{\mathcal{M},C_0} - \alpha\|u\|_{\mathcal{M}}\bigr\}
=
\begin{cases}
0, & \|p\|_{C_0}\le \alpha,\\
+\infty, & \text{otherwise}.
\end{cases}
\end{equation}
From \eqref{eq:measure_conjugate_fact} one immediately gets
\begin{equation}
\inf_{u\in\mathcal{M}(\Omega)} \bigl\{\langle u,p\rangle_{\mathcal{M},C_0} + \alpha\|u\|_{\mathcal{M}}\bigr\}
=
\begin{cases}
0, & \|p\|_{C_0}\le \alpha \ \text{(i.e.\ $\|p\|_\infty\le \alpha$)},\\
-\infty, & \text{otherwise}.
\end{cases}\label{eq:inf_step4}
\end{equation}
Hence the saddle problem \eqref{eq:saddle_start} is finite only if $\|p\|_\infty\le \alpha$.
This is the \emph{box constraint} that replaces the measure penalty, we can then rewrite \ref{eq:inf_sup_step3} as

\begin{equation}\label{eq:inf_sup_step4}
\sup_{p\in\in H^2(\Omega)\cap H^1_0(\Omega)}\
\Bigl[
-\frac12\|A^*p\|_{L^2(\Omega)}^2
-\langle z,A^*p\rangle_{L^2(\Omega)}
\Bigr], \quad \textrm{subject to} \quad \|p\|_{C_0}\le \alpha, 
\end{equation}
since $-\frac12\|A^*p+z\|_{L^2(\Omega)}^2
+\frac12\|z\|_{L^2(\Omega)}^2$ vanishes by \eqref{eq:inf_step4} for any $w$ (and p)

\subsection*{Step 5: The predual problem}
We can modify \ref{eq:inf_sup_step4} by observing that $\langle z,A^*p\rangle = \langle A^*p,z\rangle$, completing the square and changing the $sup$ by $inf$ by a sign flip to obtain the equivalent 
\begin{equation}\label{eq:predual_final}
\inf_{p\in H^2(\Omega)\cap H^1_0(\Omega)}
\Bigl[\frac12\|A^*p+z\|_{L^2(\Omega)}^2-\frac12\|z\|_{L^2(\Omega)}^2\Bigr]
\quad\text{subject to}\quad \|p\|_\infty\le \alpha.
\end{equation}
This is exactly the predual problem used by Clason--Kunisch.

\begin{remark}
The derivation shows that the predual constraint $\|p\|_\infty\le\alpha$ is nothing but the dual
expression of the measure norm penalty:
\[
\alpha\|u\|_{\mathcal{M}}
=\sup_{\|\phi\|_\infty\le\alpha} \langle u,\phi\rangle.
\]
Thus, passing from the primal to the predual can be understood as \emph{turning a nonsmooth penalty in the primal variable}
into a \emph{simple box constraint in an adjoint (dual) variable}.
\end{remark}

\section{First-order optimality conditions}\label{sec:KKT}
The next natural step in our optimization problem is to obtain a criteria that will help us decide whether we achieve a solution. First-order optimality conditions come into play as a practical way to obtain it. In the coming discussion we will use the classical KKT procedure adapted to our problem.

Recall the predual problem \ref{eq:predual_final} which we write in slightly different form
\[
\label{eq:PM_star}
\tag{$P_M^*$}
\min_{p\in H^2_0(\Omega)}\;
F(p)
\quad\text{s.t.}\quad p\in K:=\{p\in H^2_0(\Omega):\|p\|_{C_0}\le \alpha\},
\]
with
\[
F(p):=\frac12\|A^*p+z\|_{L^2(\Omega)}^2-\frac12\|z\|_{L^2(\Omega)}^2 .
\]

\paragraph{Step 1: Compute the derivative of $F$.} 
For any direction $h\in H^2_0(\Omega)$,
\[
F'(p)h
=\langle A^*p+z,\;A^*h\rangle_{L^2}
=\langle A(A^*p+z),\;h\rangle_{H^2_0(\Omega)^*,H^2_0(\Omega)}.
\]
Hence the gradient (as an element of $H^2_0(\Omega)^*$) is
\begin{equation}\label{eq:gradF}
\nabla F(p)=AA^*p+Az \in H^2_0(\Omega)^*.
\end{equation}

\paragraph{Step 2: Convex KKT condition via subdifferentials.}
Since $F$ is convex and Fr\'echet differentiable and $K$ is closed and convex, the
first-order optimality condition for $p^*\in K$ is
\[
0\in \partial \bigl(F+I_K\bigr)(p^*)
=\nabla F(p^*)+\partial I_K(p^*),
\]
i.e., there exists a multiplier $\lambda^*\in \partial I_K(p^*)=N_K(p^*)$ (normal cone) such that
\begin{equation}\label{eq:kkt_inclusion}
\nabla F(p^*)+\lambda^*=0.
\end{equation}
By definition of the normal cone,
\[
\lambda^*\in N_K(p^*)
\quad\Longleftrightarrow\quad
\langle \lambda^*,\,p-p^*\rangle_{H^2_0{}^*,H^2_0}\le 0
\quad\forall\,p\in K .
\]

\paragraph{Step 3: KKT system}
Combining \eqref{eq:gradF}--\eqref{eq:kkt_inclusion} gives the KKT conditions:
find $(p^*,\lambda^*)\in H^2_0(\Omega)\times H^2_0(\Omega)^*$ such that
\begin{equation}\label{eq:KKT_predual}
\boxed{
\begin{aligned}
&AA^*p^*+Az+\lambda^*=0 \qquad\text{in }H^2_0(\Omega)^*,\\
&\langle \lambda^*,\,p-p^*\rangle_{H^2_0{}^*,H^2_0}\le 0
\qquad \forall\,p\in H^2_0(\Omega)\ \text{with }\|p\|_{C_0}\le \alpha.
\end{aligned}}
\end{equation}

\subsection{Identification of the primal solution}\label{subsec:lambda_equals_minus_u}

We might have characterized the optimality of our predual problem but we are indeed interested in the primal problem, therefore, we need to establish a link between their solutions. We explain how the KKT multiplier for the predual box constraint can be identified with (minus) the optimal measure control. The argument uses only the saddle-point derivation and the convex optimality
condition for the $u$-subproblem.

\paragraph{Step 1: The $u$-subproblem and its first-order condition.}
If we decide to fix $p \in C_0(\Omega)$ instead of $w$ in \ref{eq:inf_sup_step3} we encounter the convex minimization problem
\begin{equation}\label{eq:u_subproblem_again}
\min_{u\in\mathcal{M}(\Omega)}\;
h_p(u):=\langle u,p\rangle_{\mathcal{M},C_0}+\alpha\|u\|_{\mathcal{M}(\Omega)}.
\end{equation}
Since $h_p$ is proper, convex, and lower semicontinuous, a minimizer $u^*$ satisfies the Fermat rule
\[
0\in \partial h_p(u^*).
\]
Using $\partial\langle u,p\rangle=\{p\}$ and the sum rule yields
\begin{equation}\label{eq:E1_sign_correct_again}
0\in p+\alpha\,\partial\|u^*\|_{\mathcal{M}(\Omega)}
\qquad\Longleftrightarrow\qquad
-p\in \alpha\,\partial\|u^*\|_{\mathcal{M}(\Omega)}.
\end{equation}
Equivalently,
\begin{equation}\label{eq:E2_normal_cone_again}
-u^*\in N_K(p^*).
\end{equation}
This is the normal-cone (variational inequality) form of the extremality relation.

\paragraph{Step 3: Identification of the KKT multiplier.}
Comparing \eqref{eq:KKT_predual_multiplier} with \eqref{eq:E2_normal_cone_again}, we see that the
normal cone element produced by the $u$-minimization is precisely $-u^*$.
Therefore one may choose the KKT multiplier in \eqref{eq:kkt_inclusion} as
\begin{equation}\label{eq:lambda_equals_minus_u}
\boxed{\ \lambda^*=-u^*\ }.
\end{equation}
With this choice, stationarity becomes
\[
\nabla F(p^*)-u^*=0,
\]
i.e.\ the primal optimal control is given by the gradient of the smooth predual objective at $p^*$.

\begin{remark}[sign convetions]
The sign in \eqref{eq:E1_sign_correct_again}--\eqref{eq:lambda_equals_minus_u} depends only on whether the saddle
form contains $+\langle u,p\rangle$ or $-\langle u,p\rangle$.
For the subproblem \eqref{eq:u_subproblem_again} with $+\langle u,p\rangle$, the correct extremality relation is
$-p\in \alpha\,\partial\|u^*\|_{\mathcal{M}}$ and hence $\lambda^*=-u^*$.    
\end{remark}

The derivation of the predual and the optimality conditions can be summarized in the following theorem proved in \cite{ClasonKunisch2009} but with a different approach.
\begin{theorem}[Clason--Kunisch, Theorem 2.4]\label{thm:clason_thm_2_4}
The dual of $(P_M^\ast)$ is $(P_M)$, and the solutions $u^\ast\in \mathcal{M}(\Omega)$ of $(P_M)$ and
$p^\ast\in H_0^2(\Omega)$ of $(P_M^\ast)$ are related by
\begin{equation}\label{eq:clason_2_4}
\left\{
\begin{aligned}
u^\ast &= AA^\ast p^\ast + Az,\\
0 &\ge \bigl\langle -u^\ast,\; p - p^\ast \bigr\rangle_{H_0^2(\Omega)^\ast,\,H_0^2(\Omega)}
\qquad \text{for all } p\in H_0^2(\Omega)\ \text{with }\|p\|_{C_0}\le \alpha.
\end{aligned}
\right.
\end{equation}
\end{theorem}

\subsection{Primal stationarity in subdifferential form}
For completeness, one may also express optimality on the primal side using the subdifferential of the
measure norm. In reduced form,
\[
\min_{u\in\mathcal{M}(\Omega)}\;
\frac12\|A^{-1}u-z\|_{L^2}^2+\alpha\|u\|_{\mathcal{M}}.
\]
The first-order condition reads
\[
0 \in A^{-*}(A^{-1}u^*-z)+\alpha\,\partial\|u^*\|_{\mathcal{M}}.
\]
With the adjoint state $p^*:=-A^{-*}(A^{-1}u^*-z)\in C_0(\Omega)$, this becomes
\[
p^*\in \alpha\,\partial\|u^*\|_{\mathcal{M}}
\quad\Longleftrightarrow\quad
\|p^*\|_{C_0}\le \alpha,\ \ \langle u^*,p^*\rangle=\alpha\|u^*\|_{\mathcal{M}}\label{eq:first_order_primal}
\]
These conditions give rise to the interesting property that the measure $u^*$ can only concentrate mass where $\|p\| = \alpha$, i.e., in the active set of the predual problem. This is know as the sparsity property and is not obvious at first glance, but we can see it by using the polar decomposition of measures, which is summarized in the following theorem \cite{Bogachev2007MeasureTheory}.   

\begin{theorem}[Polar decomposition of a finite signed (Radon) measure]\label{thm:polar_decomp_measure}
Let $\Omega$ be a locally compact Hausdorff space and let $u\in\mathcal M(\Omega)$ be a finite signed Radon
measure. Denote by $|u|$ its total variation measure. Then there exists a Borel
measurable function $\sigma:\Omega\to[-1,1]$ such that
\begin{enumerate}
\item $|\sigma(x)|=1$ for $|u|$-almost every $x\in\Omega$,
\item $u$ is absolutely continuous with respect to $|u|$ and
      \[
      \frac{du}{d|u|}=\sigma \quad\text{$|u|$-a.e.},
      \]
      in particular,
      \[
      u = \sigma\,|u| \qquad\text{in the sense that}\qquad
      \int_\Omega \varphi\,du = \int_\Omega \varphi\,\sigma\,d|u|
      \quad\forall\,\varphi\in C_c(\Omega).
      \]
\end{enumerate}
Moreover, $\sigma$ is $|u|$-a.e. uniquely determined (any two such functions agree $|u|$-a.e.).
\end{theorem}

\subsubsection*{From active set concentration to the sparsity/sign property }
To see what we will call the sparsity property, recall the dual characterization of the total variation norm
\[
\|u\|_{\mathcal M}=\sup\Bigl\{\langle u,\varphi\rangle:\ \varphi\in C_0(\Omega),\ \|\varphi\|_\infty\le 1\Bigr\},
\]
and that from \eqref{eq:first_order_primal} $p^*\in \alpha\,\partial\|u^*\|_{\mathcal M}$ is equivalent to
\[
\Bigl\|\frac{p^*}{\alpha}\Bigr\|_\infty\le 1,
\qquad
\bigl\langle u^*,\tfrac{p^*}{\alpha}\bigr\rangle=\|u^*\|_{\mathcal M} \label{eq:optm_cond}.
\]

\paragraph{Using polar decomposition.}
If $\varphi\in C_c(\Omega)$ satisfies $\|\varphi\|_\infty\le 1$ then
\[
\langle u,\varphi\rangle=\int_\Omega \varphi\,du=\int_\Omega \varphi\,\sigma\,d|u|
\le \int_\Omega |\varphi|\,d|u|\le \int_\Omega 1\,d|u|=\|u\|_{\mathcal M}.
\]
Taking $\varphi = p^*/\alpha$ and using \ref{eq:optm_cond} on the left-hand side we conclude that two inequalities must be in fact equalities. But 
\[
\int_\Omega \varphi\,\sigma\,d|u|
= \int_\Omega |\varphi|\,d|u|
\]
only if
\[
\varphi\,\sigma = |\varphi|, \quad |u|-a.e. \label{eq:sigma_cond}
\]
Also,
\[
\int_\Omega |\varphi|\,d|u| = \int_\Omega 1\,d|u| \label{eq:u_cond}
\]
only if
\[
|\varphi| = 1, \quad |u|-a.e.
\]

\paragraph{Consequence for $u^*$ and the active set.}
Apply the preceding statement \ref{eq:u_cond} to $u=u^*$ and $\varphi=p^*/\alpha$ yields
\[
|u^*|\bigl(\{x:\ |p^*(x)|<\alpha\}\bigr)=0.
\]
Equivalently, $u^*$ is \emph{identically zero as a measure} on the inactive set
$\{ |p^*|<\alpha\}$.
In addition, from \ref{eq:sigma_cond} we obtain that $\sigma^*\in\{-1, +1\}$, thus
\[
u^* \ge 0 \ \text{on } \{p^*=\alpha\},
\qquad
u^* \le 0 \ \text{on } \{p^*=-\alpha\},
\qquad |u^*|\textrm{-a.e.}
\]
in the sense of measures. In summary

\begin{theorem}[Sparsity property.]
Let $p\in C_c(\Omega)$ with $\psi\ge 0$. Then:
\begin{align*}
&\langle u^*,p\rangle=0
\quad\text{if }\operatorname{supp}p\subset\{x:\ |p^*(x)|<\alpha\},
\\
&\langle u^*,p\rangle\ge 0
\quad\text{if }\operatorname{supp}p\subset\{x:\ p^*(x)=\alpha\},
\\
&\langle u^*,p\rangle\le 0
\quad\text{if }\operatorname{supp}p\subset\{x:\ p^*(x)=-\alpha\}.
\end{align*}    
\end{theorem}

The first line follows from $|u^*|(\{|p^*|<\alpha\})=0$.
The latter two follow from the measure-inequalities $u^*\ge 0$ on $\{p^*=\alpha\}$
and $u^*\le 0$ on $\{p^*=-\alpha\}$.

\section{Example: A tensioned string under gravity}
\label{sec:example}

This section presents a fully explicit one--dimensional example of an optimal
control problem with measure--valued controls governed by an elliptic equation.
The example is motivated by a simple mechanical model: a string
subject to gravity, which we attempt to straighten using a sparse actuation.
All calculations are carried out in closed form and no heuristic arguments are
used, although we will invoke arguments based on physics to simplify the problem.

%-------------------------------------------------

\subsection{Physical model and mathematical setting}

Let $\Omega=(0,1)$.
We consider a one--dimensional tensioned string with homogeneous Dirichlet boundary conditions,
\[
y_{\mathrm{phys}}(0)=y_{\mathrm{phys}}(1)=0,
\]
subject to gravity and an additional actuator force $u$, i.e., this models a clamped beam under gravity and our control is an additional support to the beam. Note that in this case, we assume that the beam is so thin that we can ignore bending moments. Also we will consider that the string tension has unit value, therefore, the equilibrium equation is
\begin{equation}
- y_{\mathrm{phys}}'' = 1 + u
\quad \text{in } \mathcal D'(0,1),
\label{eq:physical-beam}
\end{equation}
where the control $u$ is allowed to be a bounded Radon measure,
\[
u \in \mathcal M(0,1).
\]

The constant right--hand side $1$ models a uniform gravitational load.
The use of measure--valued controls allows for both distributed and concentrated
(point) actuators.

%-------------------------------------------------

\subsection*{Gravity reference state and problem reformulation}

Let $y_g$ denote the displacement due to gravity alone, i.e.
\[
- y_g'' = 1, \qquad y_g(0)=y_g(1)=0.
\]
This problem has the explicit solution
\begin{equation}
y_g(x) = \frac{x(1-x)}{2}.
\label{eq:gravity-sag}
\end{equation}

We introduce the shifted variable
\[
y := y_{\mathrm{phys}} - y_g.
\]
Then $y$ satisfies
\begin{equation}
- y'' = u, \qquad y(0)=y(1)=0.
\label{eq:shifted-state}
\end{equation}

If the physical objective is to keep the beam as straight as possible, i.e.
$y_{\mathrm{phys}}\approx 0$, then the shifted state $y$ should track
\[
z(x) := - y_g(x) = -\frac{x(1-x)}{2}.
\]

%-------------------------------------------------

\subsection*{Primal optimal control problem}

After our modification, the problem fits exactly into the abstract framework studied until here.
The primal optimization problem reads:
\begin{equation}
\boxed{
\begin{aligned}
\min_{u \in \mathcal M(0,1)} \quad &
\frac12 \| y - z \|_{L^2(0,1)}^2
+ \alpha \|u\|_{\mathcal M(0,1)} ,\\
\text{s.t.} \quad &
- y'' = u \quad \text{in } \mathcal D'(0,1),\\
& y(0)=y(1)=0,
\end{aligned}
}
\label{eq:primal-problem}
\end{equation}
where:
\begin{itemize}
\item $y$ is the state (vertical displacement of the string),
\item $u$ is the control (actuator force),
\item $z=-y_g$ is the desired state (i.e. a straight string),
\item $\alpha>0$ is a regularization parameter.
\end{itemize}

The term $\|u\|_{\mathcal M}$ penalizes the total magnitude of applied forces and
is the source of sparsity in the optimal control.

%-------------------------------------------------

\subsection*{Predual formulation and KKT system}

Let $A=-\partial_{xx}$ with domain $H_0^2(0,1)$, so $A^* = A = -\partial_{xx}$.
Following the theory developed earlier, the predual problem leads to the
following KKT system 
\begin{align}
p^{(4)} - 1 + \lambda^* &= 0
\quad \text{in } H^{-2}(0,1),
\label{eq:kkt-reduced} \\
\langle \lambda^*,\, p - p^* \rangle &\le 0
\quad \forall p\in H_0^2(0,1)
\text{ with } \|p\|_{C_0([0,1])}\le \alpha.
\label{eq:kkt-reduced-2}
\end{align}
and the optimal control is $u^* = -\lambda^*$.

%-------------------------------------------------

\subsection{Construction of the dual solution}
To solve the system given by $\ref{eq:kkt-reduced}$ and $\ref{eq:kkt-reduced-2}$ is not trivial, because is unclear how we could combine the two expressions to obtain $p^*$ and $\lambda^*$. An option to overcome this problem is to establish (to guess) active sets, because we can take advantage of corollary (), which says $\lambda^*$ vanishes on inactive sets. In our particular problem this is actually not far-fetched, for instance, we might want a symmetric load in our string, which imposes a support (control) at the middle-length of the string. Let us take this route to proceed with our example, hence, we seek a symmetric solution such that the constraint
\[
|p^*(x)| \le \alpha
\]
is active only at the midpoint $x=\tfrac12$.
Thus
\[
p^*\!\left(\tfrac12\right)=\alpha,
\qquad
|p^*(x)|<\alpha \ \text{for } x\neq \tfrac12.
\]

On the inactive set the multiplier vanishes, and
\eqref{eq:kkt-reduced} reduces to
\[
p^{(4)} = 1.
\]

Solving it on $(0,\tfrac12)$, we obtain
\[
p^*(x) = \frac{x^4}{24} + a x^3 + c x,
\]
which satisfies $p^*(0)=0$ and $p^{*\prime\prime}(0)=0$ (since $p \in H_0^2)$.
By symmetry we set $p^*(x)=p^*(1-x)$ on $(\tfrac12,1)$.

Imposing the active region set and enforcing symmetry condition in the first derivative at the midpoint
\[
p^{*\prime}\!\left(\tfrac12\right)=0,
\qquad
p^*\!\left(\tfrac12\right)=\alpha,
\]
yields the coefficients
\[
a = -4\alpha-\frac{1}{32},
\qquad
c = 3\alpha+\frac{1}{384}.
\]
Thus
\[
p^*(x)
=
\begin{cases}
\displaystyle
\frac{x^4}{24}
-\left(4\alpha+\frac{1}{32}\right)x^3
+\left(3\alpha+\frac{1}{384}\right)x,
& 0 \le x \le \tfrac12, \\[1.2em]
\displaystyle
\frac{(1-x)^4}{24}
-\left(4\alpha+\frac{1}{32}\right)(1-x)^3
+\left(3\alpha+\frac{1}{384}\right)(1-x),
& \tfrac12 \le x \le 1.
\end{cases}
\]


%-------------------------------------------------

\subsection*{Distributional fourth derivative and jump term}
Now that we have $p^*$ we are in position to obtain $\lambda^*$ by solving for it in $\ref{eq:kkt-reduced}$. We just need to be careful because we must interpret it in the distributional sense.
The function $p^*$ is piecewise $C^4$,
with $p^*,p^{*\prime},p^{*\prime\prime}$ continuous at $x=\tfrac12$,
but $p^{*\prime\prime\prime}$ has a jump there. We can use the following lemma.

\begin{lemma}[Distributional derivative with jump]
\label{lem:jump}
Let $q\in C^{k-1}(a,b)$ be such that $q^{(k-1)}$ is piecewise $C^1$ and has a jump
at $x_0\in(a,b)$.
Then, in the sense of distributions,
\[
D^k q
=
(q^{(k)})_{\mathrm{reg}}
+
\big[q^{(k-1)}\big]_{x_0}\,\delta_{x_0},
\]
where
\[
\big[q^{(k-1)}\big]_{x_0}
=
\lim_{x\to x_0^+} q^{(k-1)}(x)
-
\lim_{x\to x_0^-} q^{(k-1)}(x).
\]
\end{lemma}

This result follows by repeated integration by parts and can be found, for example, in \cite[Section~4.2]{Evans2010PDE}.

Using in $p^{*(4)}$ yields
\[
p^{*(4)} = 1 + J\,\delta_{1/2},
\qquad
J = 48\alpha - \frac{5}{8}.
\]
Substituting into \eqref{eq:kkt-reduced} gives
\[
(1+J\delta_{1/2}) - 1 + \lambda^* = 0,
\]
hence
\[
\lambda^* = - J\,\delta_{1/2}.
\]

The optimal control is therefore
\begin{equation}
\boxed{
u^* = \left(48\alpha - \frac{5}{8}\right)\delta_{1/2}.
}
\end{equation}

The control is a single Dirac measure supported exactly at the point where the
dual constraint is active.

%-------------------------------------------------

\subsection*{Physical displacement}

The physical displacement is recovered from
\[
y_{\mathrm{phys}}^* = -p^{*\prime\prime}.
\]
On $(0,\tfrac12)$ one obtains
\[
y_{\mathrm{phys}}^*(x)
=
-\frac{x^2}{2}
+\left(24\alpha+\frac{3}{16}\right)x,
\]
and by symmetry on $(\tfrac12,1)$.
Thus the beam is piecewise quadratic with a slope kink at the midpoint, induced
by the point actuator.

\subsection{Verification of the KKT stationarity equation}
\label{subsec:distributional-verification}

We verify that the explicitly constructed pair $(p^*,\lambda^*)$ satisfies the
KKT stationarity equation
\begin{equation}
p^{*(4)} - 1 + \lambda^* = 0
\quad \text{in } \mathcal D'(0,1).
\label{eq:kkt-distributional}
\end{equation}

\subsubsection*{Distributional formulation}

Recall that the distributional fourth derivative of a function
$p\in L^1_{\mathrm{loc}}(0,1)$ is defined by
\[
\langle D^4 p, \varphi \rangle
:=
\langle p, \varphi^{(4)} \rangle
=
\int_0^1 p(x)\,\varphi^{(4)}(x)\,dx,
\qquad
\forall \varphi\in C_c^\infty(0,1).
\]
Thus, equation \eqref{eq:kkt-distributional} is equivalent to
\begin{equation}
\int_0^1 p^*(x)\,\varphi^{(4)}(x)\,dx
-
\int_0^1 \varphi(x)\,dx
+
\langle \lambda^*, \varphi \rangle
= 0
\quad
\forall \varphi\in C_c^\infty(0,1).
\label{eq:kkt-test}
\end{equation}

\subsubsection*{Structure of the dual solution}

The function $p^*$ is piecewise $C^4$ on $(0,1)$, with a possible loss of
regularity only at the midpoint $x_0:=\tfrac12$.
More precisely:
\begin{itemize}
\item $p^*\in C^2([0,1])$,
\item $p^{*\prime\prime\prime}$ has a jump discontinuity at $x_0$,
\item $p^{*(4)}(x)=1$ for all $x\in(0,1)\setminus\{x_0\}$.
\end{itemize}

The jump of the third derivative is given by
\[
J := \big[p^{*\prime\prime\prime}\big]_{x_0}
=
p^{*\prime\prime\prime}(x_0^+) - p^{*\prime\prime\prime}(x_0^-)
=
48\alpha - \frac{5}{8}.
\]

The multiplier is defined as
\[
\lambda^* := -J\,\delta_{x_0}.
\]

\subsubsection*{Computation of the distributional fourth derivative}

Let $\varphi\in C_c^\infty(0,1)$ be arbitrary.
We compute
\[
\langle D^4 p^*, \varphi \rangle
=
\int_0^1 p^*(x)\,\varphi^{(4)}(x)\,dx
=
\int_0^{x_0} p^*(x)\,\varphi^{(4)}(x)\,dx
+
\int_{x_0}^{1} p^*(x)\,\varphi^{(4)}(x)\,dx.
\]

We integrate by parts four times on each subinterval.
Since $\varphi$ has compact support in $(0,1)$, all boundary terms at $x=0$ and
$x=1$ vanish.
The only remaining boundary contributions arise at the interface $x=x_0$.

On $(0,x_0)$ one obtains
\begin{align*}
\int_0^{x_0} p^*\,\varphi^{(4)}
&=
\int_0^{x_0} p^{*(4)}\,\varphi
+
\Big[
p^*\varphi^{(3)}
- p^{*\prime}\varphi^{(2)}
+ p^{*\prime\prime}\varphi'
- p^{*\prime\prime\prime}\varphi
\Big]_{x_0^-}.
\end{align*}

On $(x_0,1)$ one similarly finds
\begin{align*}
\int_{x_0}^{1} p^*\,\varphi^{(4)}
&=
\int_{x_0}^{1} p^{*(4)}\,\varphi
-
\Big[
p^*\varphi^{(3)}
- p^{*\prime}\varphi^{(2)}
+ p^{*\prime\prime}\varphi'
- p^{*\prime\prime\prime}\varphi
\Big]_{x_0^+}.
\end{align*}

Adding both contributions yields
\begin{align}
\langle D^4 p^*, \varphi \rangle
&=
\int_0^1 p^{*(4)}(x)\,\varphi(x)\,dx
+
\Big(
\mathcal B\big|_{x_0^-}
-
\mathcal B\big|_{x_0^+}
\Big),
\label{eq:distributional-sum}
\end{align}
where
\[
\mathcal B :=
p^*\varphi^{(3)}
- p^{*\prime}\varphi^{(2)}
+ p^{*\prime\prime}\varphi'
- p^{*\prime\prime\prime}\varphi.
\]

Since $p^*$, $p^{*\prime}$, and $p^{*\prime\prime}$ are continuous at $x_0$,
all corresponding terms cancel in the difference
$\mathcal B|_{x_0^-}-\mathcal B|_{x_0^+}$.
Only the term involving $p^{*\prime\prime\prime}$ remains:
\[
\mathcal B|_{x_0^-}-\mathcal B|_{x_0^+}
=
\big(p^{*\prime\prime\prime}(x_0^+) - p^{*\prime\prime\prime}(x_0^-)\big)\,
\varphi(x_0)
=
J\,\varphi(x_0).
\]

Using $p^{*(4)}(x)=1$ away from $x_0$, equation \eqref{eq:distributional-sum}
becomes
\[
\langle D^4 p^*, \varphi \rangle
=
\int_0^1 \varphi(x)\,dx
+
J\,\varphi(x_0).
\]

Recognizing the second term as the action of a Dirac distribution, we conclude
that
\begin{equation}
D^4 p^* = 1 + J\,\delta_{x_0}
\quad \text{in } \mathcal D'(0,1).
\label{eq:p4-distribution}
\end{equation}

\subsubsection*{Verification of the KKT equation}

Substituting \eqref{eq:p4-distribution} and $\lambda^*=-J\delta_{x_0}$ into
\eqref{eq:kkt-test} yields
\[
\langle D^4 p^*, \varphi \rangle
-
\int_0^1 \varphi(x)\,dx
+
\langle \lambda^*, \varphi \rangle
=
\bigg(\int_0^1 \varphi\,dx + J\varphi(x_0)\bigg)
-
\int_0^1 \varphi\,dx
-
J\varphi(x_0)
=0.
\]

Since $\varphi\in C_c^\infty(0,1)$ was arbitrary, this proves that
\[
p^{*(4)} - 1 + \lambda^* = 0
\quad \text{in } \mathcal D'(0,1),
\]
and thus the KKT stationarity condition is satisfied in the distributional
sense.

\subsection{Threshold for vanishing optimal control}

In this section we identify the precise condition under which it is \emph{not}
optimal to apply any control in the gravity example studied in the previous
section. This phenomenon is a direct consequence of the KKT system and translates the idea that to insert a control comes with a cost -- which is not always worth to pay.

\subsection*{Unconstrained KKT equation}

Recall that the predual KKT system reads
\begin{align}
AA^* p^* + A z + \lambda^* &= 0, \label{eq:kkt-threshold-1}\\
\lambda^* &\in N_K(p^*),
\qquad K := \{p\in C_0([0,1]) : \|p\|_\infty \le \alpha\}, \label{eq:kkt-threshold-2}
\end{align}
and that the optimal control is recovered via
\[
u^* = -\lambda^*.
\]

A necessary and sufficient condition for the \emph{vanishing control}
$u^*\equiv 0$ is $\lambda^*\equiv 0$.
In this case, the stationarity equation \eqref{eq:kkt-threshold-1} reduces to the
\emph{unconstrained adjoint equation}
\begin{equation}
AA^* p_0 + A z = 0.
\label{eq:unconstrained-adjoint}
\end{equation}

Moreover, since $0\in N_K(p_0)$ if and only if $p_0\in K$, the second KKT condition
\eqref{eq:kkt-threshold-2} yields
\begin{equation}
u^*\equiv 0
\quad \Longleftrightarrow \quad
\|p_0\|_{C_0([0,1])} \le \alpha.
\label{eq:threshold-condition}
\end{equation}

Thus, the supremum norm of the unconstrained solution $p_0$ provides the exact
threshold for the appearance of nonzero control.

\subsection*{Explicit computation for the gravity example}

In the one--dimensional gravity example,
\[
A = -\partial_{xx},
\qquad
z(x) = -\frac{x(1-x)}{2},
\]
we have $z''(x)=1$ and hence $A z = -1$.
The unconstrained adjoint equation \eqref{eq:unconstrained-adjoint} becomes
\begin{equation}
p_0^{(4)} - 1 = 0
\quad \text{in } (0,1),
\label{eq:unconstrained-ode}
\end{equation}
with boundary conditions
\[
p_0(0)=p_0(1)=0,
\qquad
p_0''(0)=p_0''(1)=0,
\]
corresponding to $p_0\in H_0^2(0,1)$.

Solving \eqref{eq:unconstrained-ode} explicitly yields
\[
p_0(x)
=
\frac{1}{24}\bigl(x^4 - 2x^3 + x\bigr).
\]

A direct calculation shows that $p_0$ attains its maximum at $x=\tfrac12$, with
\[
\|p_0\|_{C_0([0,1])}
=
p_0\!\left(\tfrac12\right)
=
\frac{5}{384}.
\]

Combining \eqref{eq:threshold-condition} with the explicit value above, we obtain
the following sharp criterion.

\begin{proposition}[No--control threshold for the gravity example]
\label{prop:no-control-threshold}
For the gravity example considered in this chapter, the optimal control is
identically zero if and only if
\[
\alpha \ge \frac{5}{384}.
\]
If $\alpha < \frac{5}{384}$, then the box constraint in the predual problem
becomes active and the optimal control is nonzero.
\end{proposition}

\paragraph{Interpretation.}
The function $p_0$ can be interpreted as a \emph{sensitivity field} measuring the
marginal benefit of applying a unit force at each point.
The parameter $\alpha$ represents the cost per unit force.
Condition \eqref{eq:threshold-condition} therefore states that control is applied
only if, at some point, the benefit of actuation exceeds its cost.

In particular, for $\alpha \ge 5/384$, the gravitational deformation is tolerated
without actuation, while for smaller values of $\alpha$ the optimal strategy
introduces sparse point actuators.

\section{Conceptual comparison: predual reformulation vs.\ variational discretization (SparseFEM as sequel)}
\label{sec:comparison_sparsefem}

\subsection{A remark on alternative numerical routes}
In the previous sections of this report, our guiding principle was to \emph{avoid} a direct discretization of
controls in $\mathcal M(\Omega)$ by passing to a \emph{predual} formulation. In that approach, the predual
variable $p$ lives in a Hilbert space and the non-smooth measure norm reappears as a \emph{box constraint}
on $p$; the resulting optimality system can then be treated efficiently by a semismooth Newton method
based on active sets. This is precisely the philosophy advocated in the duality-based paper
of Clason--Kunisch. 

It is, however, not the only viable approach. A conceptually different (and, at first glance, more
``direct'') route is developed in the FEM sequel \emph{Approximation of elliptic control problems in
measure spaces with sparse solutions} (Casas--Clason--Kunisch).
The key message of that paper is that one can discretize only the \emph{state equation} by nodal finite
elements while keeping $u\in\mathcal M(\Omega)$ at the continuous level (``variational discretization''),
and nevertheless obtain an \emph{intrinsically sparse} discrete control:
the discrete optimizer can be chosen (uniquely) as a \emph{finite linear combination of Dirac measures at
mesh nodes}. 

The goal of this section is to (i) explain the main idea of this FEM approach, (ii) state its central theorem,
and (iii) compare it with the predual strategy used in this report.

%------------------------------------------------------------
\subsection{Main idea of the FEM sequel: discretize the state, and sparsity becomes nodal}
We recall the distributed measure-control model problem considered in the FEM sequel:
\[
(P)\qquad \min_{u\in\mathcal M(\Omega)}\;
J(u)=\frac12\|y-y_d\|_{L^2(\Omega)}^2 + \alpha \|u\|_{\mathcal M(\Omega)},
\quad\text{where }y\text{ solves }-\Delta y + c_0 y = u\text{ in }\Omega,\ y=0\text{ on }\Gamma .
\]

The approximation framework fixes a family of triangulations $\{\mathcal T_h\}_{h>0}$ and the nodal
$P_1$ finite element space
\[
Y_h := \{y_h\in C_0(\Omega): y_h|_{T}\in \mathbb P_1\ \forall T\in\mathcal T_h\}.
\]
The discrete state associated with a \emph{measure} $u\in\mathcal M(\Omega)$ is then defined as the unique
$y_h(u)\in Y_h$ satisfying
\begin{equation}\label{eq:sparsefem_state_discrete}
a(y_h,z_h)=\int_{\Omega_h} z_h\,du\qquad\forall z_h\in Y_h,
\end{equation}
where $a(\cdot,\cdot)$ is the bilinear form of $-\Delta + c_0$. 
This yields the discrete optimization problem
\[
(P_h)\qquad \min_{u\in\mathcal M(\Omega)}\;
J_h(u)=\frac12\|y_h(u)-y_d\|_{L^2(\Omega_h)}^2 + \alpha \|u\|_{\mathcal M(\Omega)}.
\]

\medskip
\noindent
\textbf{The conceptual surprise.}
At this point the control space has \emph{not} been discretized. Nonetheless, the FEM sequel proves that
the discrete state equation \eqref{eq:sparsefem_state_discrete} only ``sees'' $u$ through its action on the
nodal basis. This induces a canonical operator that replaces an arbitrary measure by a Dirac combination
at mesh nodes \emph{without changing the discrete state}. This is the mechanism that turns sparsity into
a concrete, finite-dimensional structure.

%------------------------------------------------------------
\subsection{The central theorem: a canonical Dirac projection $\Lambda_h$}
Let $\{x_j\}_{j=1}^{N(h)}$ denote the interior nodes of $\mathcal T_h$ and $\{e_j\}_{j=1}^{N(h)}$ the nodal basis
of $Y_h$. Define the \emph{nodal Dirac space}
\[
D_h := \left\{u_h\in\mathcal M(\Omega): u_h=\sum_{j=1}^{N(h)}\lambda_j\,\delta_{x_j}\right\},
\]
and the operators $\Pi_h:C_0(\Omega)\to Y_h$ and $\Lambda_h:\mathcal M(\Omega)\to D_h$ by
\[
\Pi_h z := \sum_{j=1}^{N(h)} z(x_j)\,e_j,
\qquad
\Lambda_h u := \sum_{j=1}^{N(h)} \langle u,e_j\rangle\,\delta_{x_j}.
\]

\begin{theorem}[Canonical nodal Dirac replacement (Casas--Clason--Kunisch)]
\label{thm:Lambda_h}
The following properties hold:
\begin{enumerate}
\item For every $u\in\mathcal M(\Omega)$, $z\in C_0(\Omega)$ and $z_h\in Y_h$,
\begin{align}
\label{eq:Lambda_pairing_FE}
\langle u,z_h\rangle &= \langle \Lambda_h u, z_h\rangle,\\
\label{eq:Lambda_pairing_interp}
\langle u,\Pi_h z\rangle &= \langle \Lambda_h u, z\rangle .
\end{align}
\item The mapping is norm-decreasing and consistent:
\begin{equation}\label{eq:Lambda_norm_and_convergence}
\|\Lambda_h u\|_{\mathcal M(\Omega)}\le \|u\|_{\mathcal M(\Omega)},\qquad
\Lambda_h u \stackrel{*}{\rightharpoonup} u\ \text{ in }\mathcal M(\Omega),\qquad
\|\Lambda_h u\|_{\mathcal M(\Omega)}\to \|u\|_{\mathcal M(\Omega)}.
\end{equation}
\item There exists $C>0$ such that for $1<p<\frac{n}{n-1}$,
\[
\|u-\Lambda_h u\|_{W^{-1,p}(\Omega)} \le C\,h^{\,1-n/p'}\|u\|_{\mathcal M(\Omega)},
\]
(with an analogous bound in $(W^{1,\infty}_0(\Omega))^*$).
\item Let $y_h$ and $\tilde y_h$ be the solutions of the discrete state equation
\eqref{eq:sparsefem_state_discrete} corresponding to $u$ and $\Lambda_h u$, respectively.
Then
\[
y_h=\tilde y_h .
\]
\end{enumerate}
\end{theorem}


\medskip
\noindent
\textbf{Interpretation.}
Item~4 is the pivotal point: \emph{once the PDE is discretized in $Y_h$, replacing $u$ by the nodal Dirac
combination $\Lambda_h u$ leaves the discrete state unchanged.} Hence, for the discrete problem,
``Dirac-at-nodes'' controls are not a heuristicthey are the \emph{canonical representatives} of equivalence
classes of measures that produce the same discrete state.

A direct consequence is that although $(P_h)$ may have multiple minimizers in $\mathcal M(\Omega)$, there is
a unique minimizer in $D_h$, and every minimizer collapses to it under $\Lambda_h$:
\begin{theorem}[Uniqueness in $D_h$]
\label{thm:unique_in_Dh}
Problem $(P_h)$ admits at least one solution. Among them there exists a unique one $\bar u_h\in D_h$.
Moreover, any other solution $\tilde u_h\in\mathcal M(\Omega)$ satisfies $\Lambda_h\tilde u_h=\bar u_h$.
\end{theorem}


Thus, the discrete control can be written uniquely as
\[
\bar u_h=\sum_{j=1}^{N(h)}\bar\lambda_j\,\delta_{x_j},
\]
and computation reduces to the finite vector $(\bar\lambda_1,\dots,\bar\lambda_{N(h)})$. 

%------------------------------------------------------------
\subsection{Optimality structure and sparsity: adjoint saturation and discrete complementarity}
The FEM sequel also derives the continuous optimality structure in the measure setting.
There exists a unique adjoint $\bar\phi\in H^2(\Omega)\cap H^1_0(\Omega)$ solving
\[
-\Delta \bar\phi + c_0 \bar\phi = \bar y - y_d\quad\text{in }\Omega,\qquad \bar\phi=0\quad\text{on }\Gamma,
\]
such that
\begin{equation}\label{eq:sparsefem_opt_23_24}
\alpha\|\bar u\|_{\mathcal M(\Omega)}+\int_\Omega \bar\phi\,d\bar u=0,
\qquad
\|\bar\phi\|_{C_0(\Omega)}
\begin{cases}
=\alpha,& \bar u\neq 0,\\
\le \alpha,& \bar u=0.
\end{cases}
\end{equation}
In terms of the Jordan decomposition $\bar u=\bar u^+-\bar u^-$, one deduces the saturation/support rule
\begin{equation}\label{eq:sparsefem_support}
\supp(\bar u^+)\subset\{x:\bar\phi(x)=-\alpha\},
\qquad
\supp(\bar u^-)\subset\{x:\bar\phi(x)=+\alpha\},
\end{equation}
hence $\bar u\equiv 0$ on $\{|\bar\phi|<\alpha\}$. 

At the discrete level, the same geometry becomes a \emph{componentwise} complementarity condition. Introducing
the discrete adjoint $\bar\phi_h\in Y_h$ and the nodal Dirac control $\bar u_h\in D_h$,
the variational inequality defining the normal cone to the $C_0$-ball can be rewritten as
\begin{equation}\label{eq:sparsefem_complementarity}
\bar u_h + \max\!\bigl(0,\,-\bar u_h+\bar\phi_h-\alpha\bigr)
+ \min\!\bigl(0,\,-\bar u_h+\bar\phi_h+\alpha\bigr)=0,
\end{equation}
understood componentwise in the coefficient vectors $(\lambda_j)$ and $(\phi_j)$. 
This is again amenable to a locally superlinearly convergent semismooth Newton method in finite dimension. 

%------------------------------------------------------------
\subsection{Comparison with the predual strategy used in this report}
We now juxtapose the above FEM philosophy with the predual philosophy we currently follow.

\paragraph{(i) Where nonsmoothness is handled.}
\begin{itemize}
\item \textbf{Predual route (this report).} Nonsmoothness is shifted into a \emph{box constraint} on the Hilbert-space
variable $p$, and the optimality system is solved as a semismooth equation
\[
F(p)=AA^*p+\max(0,c(p-\alpha))+\min(0,c(p+\alpha))+Az=0,
\]
based on the semismooth projector $P_\alpha(p)=\max(0,p-\alpha)+\min(0,p+\alpha)$ and its Newton derivative
$\partial_N P_\alpha(p)h=h\,\chi_{\{|p|>\alpha\}}$. 
\item \textbf{FEM route (SparseFEM).} Nonsmoothness stays in the measure norm, but discretization of the \emph{state}
induces the canonical Dirac representative $\Lambda_h u$ and yields the componentwise complementarity equation
\eqref{eq:sparsefem_complementarity} for the nodal coefficients. 
\end{itemize}

\paragraph{(ii) What ``sparsity'' means computationally.}
\begin{itemize}
\item \textbf{Predual.} Sparsity is encoded by the \emph{active set} $\{|p|=\alpha\}$ (or $\{|p|>\alpha\}$ at the
regularized level), which enters directly in the Newton derivative via the characteristic function
$\chi_{\{|p|>\alpha\}}$. 
\item \textbf{SparseFEM.} Sparsity is encoded by the smallness of the \emph{saturation set} $\{|\bar\phi|=\alpha\}$ in the
continuous optimality system \eqref{eq:sparsefem_opt_23_24}--\eqref{eq:sparsefem_support}, and, after discretization,
by the fact that the discrete optimizer \emph{is literally a finite sum of Diracs at nodes}. 
\end{itemize}

\paragraph{(iii) Dictionary between variables.}
In SparseFEM one has the subgradient characterization $-\bar\phi\in \alpha\,\partial\|\cdot\|_{\mathcal M}(\bar u)$,
equivalently $\alpha\lambda=-\bar\phi$ for a subgradient $\lambda\in C_0(\Omega)$. 
In the predual approach, the Hilbert-space variable $p$ is constrained by $|p|\le\alpha$ and the active set
determines the structure of the optimal control. 
Up to the sign convention, it is therefore natural to identify
\[
p \ \approx\ -\bar\phi,
\qquad
\{|p|=\alpha\}\ \approx\ \{|\bar\phi|=\alpha\},
\]
so that ``box activity'' in the predual formulation corresponds to ``adjoint saturation'' determining the
support of the measure control in the primal formulation.

\paragraph{(iv) What the FEM sequel adds conceptually.}
The predual route motivates \emph{why} one should solve for $p$ in a Hilbert space rather than discretizing measures directly. 
The FEM sequel complements this by showing that a straightforward nodal FEM approximation \emph{automatically}
yields a canonical sparse surrogate of a measure control (Theorem~\ref{thm:Lambda_h}), thereby justifying the
common practice of representing discrete measures by nodal Dirac sums\emph{without losing the structural properties
imposed by the measure norm}. 


\section{Numerics}
\label{seq:numerics}

In the predual formulation for measure controls \eqref{eq:PM_star}
the constraint is a pointwise \emph{box constraint} on the dual variable $p$, i.e.\ $-\alpha\le p(x)\le \alpha$ for all $x\in\Omega$
(using $H^2_0(\Omega)\hookrightarrow C_0(\Omega)$).
The associated KKT system \eqref{eq:KKT_predual} has a Lagrange multiplier $\lambda^\ast$ that lives naturally in the dual space $H^2_0(\Omega)^\ast$ and, in general, is \emph{not} an $L^2$-function.
This is problematic numerically:
\begin{itemize}
\item Discretizations and Newton-type methods typically require multipliers that can be represented in the same discrete space as the state/adjoint,
      e.g.\ piecewise polynomials or grid functions (hence in an $L^2$-like space).
\item The box constraint is nonsmooth; one needs a structure that yields a (semi)smooth nonlinear equation amenable to fast Newton solvers.
\end{itemize}

To overcome both issues, we replace the hard constraint by a \emph{Moreau--Yosida regularization} of the indicator of the box constraint set.
This produces a smooth penalization of constraint violations and yields multipliers that belong to $W^{1,\infty}(\Omega)\subset L^2(\Omega)$.
We then solve the resulting regularized optimality system by a semismooth Newton method.

\subsection{Moreau--Yosida regularization of the box constraint}

For $c>0$, consider the regularized predual problem
\[
\tag{$P_{M,c}^\ast$}
\label{eq:PM_star_r}
\min_{p\in H^2_0(\Omega)}\;
\frac12\|A^\ast p + z\|_{L^2(\Omega)}^2-\frac12\|z\|_{L^2(\Omega)}^2
+\frac{1}{2c}\|\max(0,c(p-\alpha))\|_{L^2(\Omega)}^2
+\frac{1}{2c}\|\min(0,c(p+\alpha))\|_{L^2(\Omega)}^2,
\]
where $\max$ and $\min$ are understood pointwise a.e.\ in $\Omega$.
This functional is strictly convex, hence admits a unique minimizer $p_c\in H^2_0(\Omega)$.
Its first-order optimality conditions are (in strong form)
\begin{equation}\label{eq:MY_opt_system}
\begin{cases}
AA^\ast p_c + Az + \lambda_c = 0,\\
\lambda_c = \max(0,c(p_c-\alpha))+\min(0,c(p_c+\alpha)),
\end{cases}
\end{equation}
and satisfy $\lambda_c\in W^{1,\infty}(\Omega)$ in particular $\lambda_c\in L^2(\Omega)$; see \cite{ClasonKunisch2009}.

\subsection*{Convergence to the original (predual) solution}

We now state and prove the key convergence result showing that \ref{eq:PM_star_r} approximates \eqref{eq:PM_star} as $c\to\infty$.

\begin{theorem}[Convergence of the Moreau--Yosida regularization]\label{thm:MY_convergence}
Let $(p_c,\lambda_c)\in H^2_0(\Omega)\times H^2_0(\Omega)^\ast$ solve \eqref{eq:MY_opt_system} for $c>0$.
Let $(p^\ast,\lambda^\ast)\in H^2_0(\Omega)\times H^2_0(\Omega)^\ast$ be the unique solution of the KKT system of the unregularized problem, i.e.
\[
AA^\ast p^\ast + Az + \lambda^\ast = 0,
\qquad
\langle \lambda^\ast, p-p^\ast\rangle_{H^2_0(\Omega)^\ast,H^2_0(\Omega)}\le 0
\ \ \forall p\in H^2_0(\Omega):\ \|p\|_{C_0(\Omega)}\le\alpha.
\]
Then, as $c\to\infty$,
\[
p_c \to p^\ast \quad\text{strongly in } H^2_0(\Omega),
\qquad
\lambda_c \rightharpoonup \lambda^\ast \quad\text{weakly in } H^2_0(\Omega)^\ast.
\]
\end{theorem}

\begin{proof}

\medskip\noindent
\textbf{Step 1: A key inequality.}
From the pointwise definition of $\lambda_c$ in \eqref{eq:MY_opt_system},
one checks (pointwise) that
\[
\lambda_c(x)\,p_c(x)=
\begin{cases}
c(p_c(x)-\alpha)p_c(x), & p_c(x)\ge \alpha,\\
0, & |p_c(x)|<\alpha,\\
c(p_c(x)+\alpha)p_c(x), & p_c(x)\le -\alpha,
\end{cases}
\]
and hence
\begin{equation}\label{eq:key_lambda_pc}
\langle \lambda_c,p_c\rangle_{L^2(\Omega)} \ge \frac1c\|\lambda_c\|_{L^2(\Omega)}^2.
\end{equation}
(Indeed, on $\{p_c\ge\alpha\}$ we have $\lambda_c=c(p_c-\alpha)\ge 0$ and $\lambda_c p_c = \lambda_c(\lambda_c/c+\alpha)\ge \lambda_c^2/c$, and similarly on $\{p_c\le -\alpha\}$.)

\medskip\noindent
\textbf{Step 2: Uniform bounds in $H^2_0(\Omega)\times H^2_0(\Omega)^\ast$.}
Test the variational form of the first equation in \eqref{eq:MY_opt_system} with $v=p_c$:
\[
\|A^\ast p_c\|_{L^2(\Omega)}^2 + \langle z, A^\ast p_c\rangle_{L^2(\Omega)}
+ \langle \lambda_c, p_c\rangle_{H^2_0(\Omega)^\ast,H^2_0(\Omega)} = 0.
\]
Using \eqref{eq:key_lambda_pc} and Cauchy--Schwarz for $\langle z, A^\ast p_c\rangle$ yields
\[
\|A^\ast p_c\|_{L^2(\Omega)}^2 + \frac1c\|\lambda_c\|_{L^2(\Omega)}^2
\le \|A^\ast p_c\|_{L^2(\Omega)}\|z\|_{L^2(\Omega)},
\]
hence $\|A^\ast p_c\|_{L^2(\Omega)}\le \|z\|_{L^2(\Omega)}$ for all $c$.
Using the first equation again,
\[
\|\lambda_c\|_{H^2_0(\Omega)^\ast}
= \sup_{\substack{v\in H^2_0(\Omega)\\ \|v\|_{H^2_0}\le 1}}
\langle \lambda_c, v\rangle
\le 
\sup_{\|v\|_{H^2_0}\le 1} \bigl(\langle A^\ast p_c, A^\ast v\rangle + \langle z, A^\ast v\rangle \bigr)
\le K,
\]
for some constant $K$ independent of $c$ (here we use the norm equivalence assumption for $A^\ast$ on $H^2_0(\Omega)$ as in the paper).
Thus $(p_c,\lambda_c)$ is uniformly bounded in $H^2_0(\Omega)\times H^2_0(\Omega)^\ast$.

\medskip\noindent
\textbf{Step 3: Weak limits and the limiting first equation.}
By Banach--Alaoglu, there exists a subsequence (not relabeled) and a pair $(\tilde p,\tilde\lambda)$ such that
\[
(p_c,\lambda_c)\rightharpoonup (\tilde p,\tilde\lambda)
\quad\text{in }H^2_0(\Omega)\times H^2_0(\Omega)^\ast.
\]
Passing to the limit in the weak form of the first equation in \eqref{eq:MY_opt_system} gives
\begin{equation}\label{eq:limit_first_eq}
AA^\ast \tilde p + Az + \tilde\lambda = 0
\quad\text{in }H^2_0(\Omega)^\ast.
\end{equation}

\medskip\noindent
\textbf{Step 4: Feasibility of the limit $\tilde p$.}
From the pointwise expression for $\lambda_c$ we compute
\[
\frac1c\|\lambda_c\|_{L^2(\Omega)}^2
= c\|\max(0,p_c-\alpha)\|_{L^2(\Omega)}^2
+ c\|\min(0,p_c+\alpha)\|_{L^2(\Omega)}^2.
\]
The estimate in Step 2 yields $\frac1c\|\lambda_c\|_{L^2}^2\le \|z\|_{L^2}^2$, hence
\[
\|\max(0,p_c-\alpha)\|_{L^2}^2 \le \frac{1}{c}\|z\|_{L^2}^2 \to 0,
\qquad
\|\min(0,p_c+\alpha)\|_{L^2}^2 \le \frac{1}{c}\|z\|_{L^2}^2 \to 0.
\]
Since $H^2_0(\Omega)\hookrightarrow L^2(\Omega)$ compactly, we have (after subsequence extraction) $p_c\to\tilde p$ strongly in $L^2(\Omega)$, so the above implies
\[
-\alpha \le \tilde p(x)\le \alpha \quad\text{for a.e.\ }x\in\Omega,
\]
i.e.\ $\|\tilde p\|_{C_0(\Omega)}\le \alpha$ (recall $\tilde p\in H^2_0(\Omega)\hookrightarrow C_0(\Omega)$).

\medskip\noindent
\textbf{Step 5: Strong convergence $p_c\to\tilde p$ in $H^2_0(\Omega)$.}
By optimality of $p_c$ for $(P_{M,c}^\ast)$ and since the regularization terms are nonnegative,
\[
\frac12\|A^\ast p_c+z\|_{L^2}^2
\le
\frac12\|A^\ast p+z\|_{L^2}^2
\quad \forall p\in H^2_0(\Omega)\text{ with }\|p\|_{C_0}\le\alpha.
\]
Taking $\limsup_{c\to\infty}$ and using weak lower semicontinuity yields
\[
\limsup_{c\to\infty}\frac12\|A^\ast p_c+z\|_{L^2}^2
\le
\frac12\|A^\ast \tilde p+z\|_{L^2}^2
\le
\liminf_{c\to\infty}\frac12\|A^\ast p_c+z\|_{L^2}^2,
\]
so $\|A^\ast p_c\|_{L^2}\to\|A^\ast \tilde p\|_{L^2}$.
Together with the weak convergence $p_c\rightharpoonup \tilde p$ in $H^2_0$ and the norm equivalence induced by $A^\ast$ (assumption (A) in the paper), this implies $p_c\to\tilde p$ strongly in $H^2_0(\Omega)$.

\medskip\noindent
\textbf{Step 6: Passing to the limiting variational inequality.}
For every feasible $p$ (i.e.\ $\|p\|_{C_0}\le\alpha$), the monotonicity of the max/min terms gives
\[
\langle \lambda_c, p-p_c\rangle_{H^2_0(\Omega)^\ast,H^2_0(\Omega)} \le 0.
\]
Using $\lambda_c\rightharpoonup \tilde\lambda$ in $H^2_0(\Omega)^\ast$ and $p_c\to\tilde p$ in $H^2_0(\Omega)$, we obtain
\[
\langle \tilde\lambda, p-\tilde p\rangle_{H^2_0(\Omega)^\ast,H^2_0(\Omega)} \le 0
\quad \forall p\in H^2_0(\Omega):\ \|p\|_{C_0}\le\alpha.
\]
Together with \eqref{eq:limit_first_eq}, this shows that $(\tilde p,\tilde\lambda)$ satisfies the unregularized KKT system.
By uniqueness of the solution of the KKT system (as in the paper), we conclude $\tilde p=p^\ast$ and $\tilde\lambda=\lambda^\ast$.

\medskip\noindent
\textbf{Step 7: Conclusion for the full family.}
Since every weakly convergent subsequence has the same limit, the whole family satisfies
$p_c\to p^\ast$ in $H^2_0(\Omega)$ and $\lambda_c\rightharpoonup \lambda^\ast$ in $H^2_0(\Omega)^\ast$ as $c\to\infty$.
\end{proof}

Theorem~\ref{thm:MY_convergence} provides the rigorous justification for the numerical strategy:
\begin{enumerate}
\item Replace the original box constraint by a Moreau--Yosida penalty $(P_{M,c}^\ast)$.
      This yields a smooth objective and an $L^2$-representable multiplier
      \[
      \lambda_c = \max(0,c(p_c-\alpha))+\min(0,c(p_c+\alpha)),
      \]
      which is directly computable on a grid/finite element space.
\item Solve the regularized optimality system \eqref{eq:MY_opt_system} by a semismooth Newton method:
      the nonsmooth projection-type operator becomes \emph{semismooth}, with a Newton derivative involving the active set
      $\{x:\ |p_c(x)|>\alpha\}$ (cf.\ \cite{ClasonKunisch2009}).
\item Increase $c$ (or choose $c$ sufficiently large) to approximate the original solution:
      Theorem~\ref{thm:MY_convergence} guarantees that $p_c$ converges to the true predual solution $p^\ast$ in $H^2_0(\Omega)$.
      Consequently, the control reconstructed from the predual variable (via $u^\ast = AA^\ast p^\ast + Az$ in the measure case)
      is approximated by the computable expression $u_c = AA^\ast p_c + Az$.
\end{enumerate}

In conclusion, this regularization scheme is not only an algorithmic trick to make Newton work; it is a \emph{consistent approximation} of the original constrained problem, and Theorem~\ref{thm:MY_convergence} is the bridge between the computed $(p_c,\lambda_c)$ and the true KKT pair $(p^\ast,\lambda^\ast)$.

%------------------------------------------------------------
\subsection{Semismooth Newton method for the regularized predual problem}
\label{sec:ssn}

\paragraph{Starting point: the regularized optimality system.}
Fix a Moreau--Yosida parameter $c>0$ and recall the regularized optimality system (cf.\ \cite[Sec.~3.2]{ClasonKunisch2011})
\begin{equation}\label{eq:opt_sys_reg}
AA^\ast p_c + \lambda_c + Az = 0,
\qquad
\lambda_c = \max\!\bigl(0,c(p_c-\alpha)\bigr)+\min\!\bigl(0,c(p_c+\alpha)\bigr),
\end{equation}
where $\max$ and $\min$ are taken pointwise a.e.\ in $\Omega$.
The goal is to solve \eqref{eq:opt_sys_reg} efficiently for $p_c\in H_0^2(\Omega)$.

\paragraph{Intuitive idea (why ``active sets'' appear).}
The mapping
\[
p \longmapsto \max\!\bigl(0,c(p-\alpha)\bigr)+\min\!\bigl(0,c(p+\alpha)\bigr)
\]
is \emph{piecewise affine} in $p$:
\[
\max(0,c(p-\alpha))=
\begin{cases}
c(p-\alpha), & p>\alpha,\\
0, & p\le \alpha,
\end{cases}
\qquad
\min(0,c(p+\alpha))=
\begin{cases}
0, & p\ge -\alpha,\\
c(p+\alpha), & p<- \alpha.
\end{cases}
\]
Hence, if we already knew where $p$ violates the bounds $\pm\alpha$, the term is simply linear there and zero elsewhere.
This motivates the following strategy:
\begin{quote}
\emph{Guess the regions where $p$ is active (i.e.\ outside $[-\alpha,\alpha]$), then solve the linear equation corresponding to that guess, then update the guess.}
\end{quote}
Semismooth Newton makes this precise and yields a fast method with superlinear convergence.

%------------------------------------------------------------
\subsubsection{Reformulation as a semismooth equation}

Define the nonlinear operator $F:H_0^2(\Omega)\to H_0^2(\Omega)^\ast$ by
\begin{equation}\label{eq:F_def_paper}
F(p):= AA^\ast p \;+\; \max\!\bigl(0,c(p-\alpha)\bigr)\;+\;\min\!\bigl(0,c(p+\alpha)\bigr)\;+\;Az.
\end{equation}
Then \eqref{eq:opt_sys_reg} is equivalent to the root-finding problem
\begin{equation}\label{eq:F_root}
F(p)=0 \quad \text{in } H_0^2(\Omega)^\ast.
\end{equation}

Introduce the projection-type operator
\begin{equation}\label{eq:Palpha}
P_\alpha(p):=\max(0,p-\alpha)+\min(0,p+\alpha),
\end{equation}
so that $F(p)=AA^\ast p + c\,P_\alpha(p)+Az$.

\paragraph{Semismoothness and Newton derivative (as in the paper).}
It is known (see \cite[Ex.~8.14]{ItoKunisch2008}) that $P_\alpha$ is semismooth from $L^q(\Omega)$ to $L^p(\Omega)$ if $q>p$,
and that a Newton derivative is given by
\begin{equation}\label{eq:Newton_derivative_Palpha}
\partial_N P_\alpha(p)h = h\,\chi_{\{|p|>\alpha\}}
=
\begin{cases}
h(x), & |p(x)|>\alpha,\\
0, & |p(x)|\le \alpha.
\end{cases}
\end{equation}
Since $AA^\ast$ is linear and Fr\'echet differentiable, it follows that $F$ is semismooth and
\begin{equation}\label{eq:Newton_derivative_F}
\partial_N F(p)h \;=\; AA^\ast h \;+\; c\,h\,\chi_{\{|p|>\alpha\}}.
\end{equation}

%------------------------------------------------------------
\subsubsection{Derivation of the semismooth Newton step}

Given an iterate $p_k\in H_0^2(\Omega)$, the semismooth Newton update is defined by
\begin{equation}\label{eq:ssn_step_abstract}
\partial_N F(p_k)\,(p_{k+1}-p_k) = -F(p_k).
\end{equation}

\paragraph{Active and inactive sets.}
Set
\begin{equation}\label{eq:active_sets_paper}
A_k^+ := \{x\in\Omega:\ p_k(x)>\alpha\},\qquad
A_k^- := \{x\in\Omega:\ p_k(x)<-\alpha\},\qquad
A_k := A_k^+\cup A_k^-.
\end{equation}
Then $\chi_{\{|p_k|>\alpha\}}=\chi_{A_k}$ and \eqref{eq:ssn_step_abstract} becomes
\[
AA^\ast(p_{k+1}-p_k)+c(p_{k+1}-p_k)\chi_{A_k} = -\Bigl(AA^\ast p_k + cP_\alpha(p_k)+Az\Bigr).
\]
After rearranging and using $P_\alpha(p_k)=(p_k-\alpha)\chi_{A_k^+}+(p_k+\alpha)\chi_{A_k^-}$,
one obtains the linear equation for $p_{k+1}$:
\begin{equation}\label{eq:ssn_step_strong}
\bigl(AA^\ast + c\,\chi_{A_k}\bigr)p_{k+1}
=
-Az + c\alpha\,\chi_{A_k^+} - c\alpha\,\chi_{A_k^-}.
\end{equation}

\paragraph{Weak form (the form used in the paper).}
Testing \eqref{eq:ssn_step_strong} with $v\in H_0^2(\Omega)$ gives:
find $p_{k+1}\in H_0^2(\Omega)$ such that
\begin{equation}\label{eq:ssn_step_weak}
\langle A^\ast p_{k+1},A^\ast v\rangle_{L^2}
+
c\langle p_{k+1}\chi_{A_k},v\rangle_{L^2}
=
-\langle z, A^\ast v\rangle_{L^2}
+
c\alpha\langle \chi_{A_k^+}-\chi_{A_k^-},v\rangle_{L^2}
\end{equation}
for all $v\in H_0^2(\Omega)$.

%------------------------------------------------------------
\subsubsection{Algorithm}

\begin{algorithm}\label{alg:ssn_paper}
\begin{enumerate}
\item Choose $p_0\in H_0^2(\Omega)$ and set $k=0$.
\item Repeat:
\begin{enumerate}
\item[(i)] Define active sets
\[
A_k^+ := \{p_k>\alpha\},\qquad A_k^- := \{p_k<-\alpha\},\qquad A_k:=A_k^+\cup A_k^-.
\]
\item[(ii)] Compute $p_{k+1}\in H_0^2(\Omega)$ by solving \eqref{eq:ssn_step_weak}.
\item[(iii)] Set $k\leftarrow k+1$.
\end{enumerate}
\item Stop if $A_k^+=A_{k-1}^+$ and $A_k^-=A_{k-1}^-$.
\end{enumerate}
\end{algorithm}

\paragraph{Why the stopping criterion makes sense.}
If the active sets no longer change, the Newton derivative stays the same and the right-hand side in \eqref{eq_ssn_step_weak} is consistent with the nonlinear term.
Consequently, the computed iterate already solves the nonlinear equation $F(p)=0$.

\begin{proposition}[Active-set stationarity implies exactness]\label{prop:active_set_stop}
If $A_{k+1}^+=A_k^+$ and $A_{k+1}^-=A_k^-$, then $p_{k+1}$ satisfies $F(p_{k+1})=0$, i.e.\ it solves \eqref{eq:opt_sys_reg}.
\end{proposition}

\begin{proof}
Fix the sets $A_k^\pm$ and note that \eqref{eq:ssn_step_weak} has a unique solution for these fixed sets.
If $A_{k+1}^\pm=A_k^\pm$, then on $A_{k+1}^+$ we have $p_{k+1}>\alpha$ and therefore
\[
c\,p_{k+1}\chi_{A_{k+1}^+}-c\alpha\chi_{A_{k+1}^+}=\max(0,c(p_{k+1}-\alpha)),
\]
and analogously on $A_{k+1}^-$,
\[
c\,p_{k+1}\chi_{A_{k+1}^-}+c\alpha\chi_{A_{k+1}^-}=\min(0,c(p_{k+1}+\alpha)).
\]
Inserting these identities into \eqref{eq:ssn_step_weak} shows that \eqref{eq:ssn_step_weak} is equivalent to
$\langle F(p_{k+1}),v\rangle=0$ for all $v\in H_0^2(\Omega)$, i.e.\ $F(p_{k+1})=0$ in $H_0^2(\Omega)^\ast$.
\end{proof}

%------------------------------------------------------------
\subsubsection{Superlinear convergence (paper theorem and proof in steps)}

\begin{theorem}[Superlinear convergence of Algorithm~\ref{alg:ssn_paper}]
\label{thm:ssn_superlinear_paper}
If $\|p_c-p_0\|_{H_0^2(\Omega)}$ is sufficiently small, then the iterates $\{p_k\}$ generated by
Algorithm~\ref{alg:ssn_paper} converge \emph{superlinearly} in $H_0^2(\Omega)$ to the unique solution $p_c$ of \eqref{eq:opt_sys_reg}.
\end{theorem}

\begin{proof}
We follow \cite[Thm.~3.3]{ClasonKunisch2011}, and spell out the key estimate.

\paragraph{Step 1: Reduce to a uniform inverse bound.}
Since $F$ is semismooth, standard semismooth Newton theory implies superlinear convergence provided
$(\partial_N F(p))^{-1}$ exists and is locally uniformly bounded near $p_c$
(see \cite[Thm.~8.16]{ItoKunisch2008}).

\paragraph{Step 2: Invertibility of the Newton derivative.}
Fix a measurable set $A\subset\Omega$ and consider the linear operator
\[
\mathcal{L}_A: H_0^2(\Omega)\to H_0^2(\Omega)^\ast,
\qquad
\langle \mathcal{L}_A \varphi, v\rangle
:= \langle A^\ast\varphi,A^\ast v\rangle_{L^2}
+ c\langle \chi_A\varphi, v\rangle_{L^2}.
\]
This is precisely $\partial_NF(p)$ with $A=\{|p|>\alpha\}$.
By the assumptions on $A^\ast$ used throughout the paper (in particular that $\|A^\ast(\cdot)\|_{L^2}$ defines an equivalent norm on $H_0^2(\Omega)$),
the bilinear form
\[
a_A(\varphi,v):=\langle A^\ast\varphi,A^\ast v\rangle_{L^2}+c\langle \chi_A\varphi,v\rangle_{L^2}
\]
is continuous and coercive on $H_0^2(\Omega)$, with coercivity constant \emph{independent of $A$}
(since $c\langle\chi_A\varphi,\varphi\rangle_{L^2}\ge 0$ only improves coercivity).
Hence, by Lax--Milgram, for every $g\in H_0^2(\Omega)^\ast$ there exists a unique $\varphi\in H_0^2(\Omega)$ such that
\begin{equation}\label{eq:LM_variational}
\langle A^\ast\varphi,A^\ast v\rangle_{L^2}+c\langle \chi_A\varphi,v\rangle_{L^2}
=\langle g,v\rangle_{H_0^2(\Omega)^\ast,H_0^2(\Omega)}
\qquad \forall v\in H_0^2(\Omega).
\end{equation}
Thus $\mathcal{L}_A$ is invertible.

\paragraph{Step 3: Uniform bound for the inverse.}
Coercivity of $a_A$ yields the estimate
\[
\|\varphi\|_{H_0^2(\Omega)} \le C \|g\|_{H_0^2(\Omega)^\ast},
\]
where $C$ depends only on $A$ (the PDE operator) and $\Omega$, but \emph{not} on $A\subset\Omega$.
Equivalently,
\[
\|\mathcal{L}_A^{-1}\|_{\mathcal{L}(H_0^2(\Omega)^\ast,H_0^2(\Omega))}\le C,
\]
uniformly over all active sets $A$.

\paragraph{Step 4: Apply semismooth Newton theory.}
Taking $A=\{|p|>\alpha\}$, the uniform inverse bound from Step~3 gives the required hypothesis in \cite[Thm.~8.16]{ItoKunisch2008}.
Therefore, for $p_0$ sufficiently close to $p_c$, the semismooth Newton iterates are well-defined and converge superlinearly to $p_c$ in $H_0^2(\Omega)$.
\end{proof}

\paragraph{Remark (link to primal--dual active sets).}
Algorithm~\ref{alg:ssn_paper} is the primal--dual active set strategy in disguise:
the update of $A_k^\pm$ is the ``active set'' step, and \eqref{eq:ssn_step_weak} is the corresponding linearized KKT system.
The equivalence between both interpretations is classical; see \cite{HintermuellerItoKunisch2002}.





\bibliographystyle{plain} % numeric
\bibliography{refs}

\end{document}
